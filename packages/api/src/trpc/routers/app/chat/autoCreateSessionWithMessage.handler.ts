import { TRPCError } from "@trpc/server";

import type { AutoCreateSessionWithMessageInput } from "@kdx/validators/trpc/app";
import { appRepository, chatRepository } from "@kdx/db/repositories";
import { chatAppId } from "@kdx/shared";

import type { TProtectedProcedureContext } from "../../../procedures";
import { AiStudioService } from "../../../../internal/services/ai-studio.service";
import { ChatService } from "../../../../internal/services/chat.service";

// Helper para buscar modelo preferido seguindo hierarquia usando Service Layer
async function getPreferredModelHelper(
  teamId: string,
  userId: string,
): Promise<{
  source: "user_config" | "ai_studio_default" | "first_available";
  modelId: string;
  model: any;
  config?: any;
  teamConfig?: any;
}> {
  // ‚úÖ 1¬™ Prioridade: Verificar preferredModelId nas configura√ß√µes de USU√ÅRIO
  try {
    const userConfigs = await appRepository.findUserAppTeamConfigs({
      appId: chatAppId,
      teamIds: [teamId],
      userIds: [userId],
    });

    const userConfig = userConfigs[0]; // S√≥ haver√° um config por usu√°rio/app/team
    const preferredModelId = userConfig
      ? (userConfig.config as any)?.personalSettings?.preferredModelId
      : null;

    if (preferredModelId) {
      try {
        const model = await AiStudioService.getModelById({
          modelId: preferredModelId,
          teamId,
          requestingApp: chatAppId,
        });

        if (model) {
          return {
            source: "user_config",
            modelId: model.id,
            model,
            config: userConfig?.config,
          };
        }
      } catch (error) {
        console.log(
          "‚ö†Ô∏è [PREFERRED_MODEL] preferredModelId do User Config inv√°lido, continuando para AI Studio",
        );
      }
    } else {
      console.log(
        "‚ùå [PREFERRED_MODEL] Nenhum preferredModelId encontrado no User Config",
      );
    }
  } catch (error) {
    console.log(
      "‚ö†Ô∏è [PREFERRED_MODEL] Erro ao buscar User Config, continuando para AI Studio:",
      error,
    );
  }

  // ‚úÖ 2¬™ Prioridade: Buscar modelo padr√£o no AI Studio via Service Layer
  try {
    const defaultModelConfig = await AiStudioService.getDefaultModel({
      teamId,
      requestingApp: chatAppId,
    });

    if (defaultModelConfig.model) {
      console.log(
        "‚úÖ [PREFERRED_MODEL] Modelo padr√£o do AI Studio encontrado:",
        defaultModelConfig.model.universalModelId,
      );
      return {
        source: "ai_studio_default",
        modelId: defaultModelConfig.model.id,
        model: defaultModelConfig.model,
        teamConfig: defaultModelConfig,
      };
    }
  } catch (error) {
    console.log(
      "‚ö†Ô∏è [PREFERRED_MODEL] Erro ao buscar modelo padr√£o do AI Studio:",
      error,
    );
  }

  // ‚úÖ 3¬™ Prioridade: Buscar primeiro modelo ativo dispon√≠vel via Service Layer
  try {
    const availableModels = await AiStudioService.getAvailableModels({
      teamId,
      requestingApp: chatAppId,
    });

    const firstActiveModel = (availableModels || []).find(
      (m: any) => m.teamConfig?.enabled,
    );

    if (firstActiveModel) {
      console.log(
        "üîÑ [PREFERRED_MODEL] Usando primeiro modelo ativo como fallback:",
        firstActiveModel.universalModelId,
      );
      return {
        source: "first_available",
        modelId: firstActiveModel.id,
        model: firstActiveModel,
        teamConfig: firstActiveModel.teamConfig,
      };
    }
  } catch (error) {
    console.log(
      "‚ö†Ô∏è [PREFERRED_MODEL] Erro ao buscar modelos dispon√≠veis:",
      error,
    );
  }

  throw new TRPCError({
    code: "NOT_FOUND",
    message: "Nenhum modelo de IA dispon√≠vel. Configure modelos no AI Studio.",
  });
}

export async function autoCreateSessionWithMessageHandler({
  input,
  ctx,
}: {
  input: AutoCreateSessionWithMessageInput;
  ctx: TProtectedProcedureContext;
}) {
  const teamId = ctx.auth.user.activeTeamId;
  const userId = ctx.auth.user.id;

  try {
    console.log(
      "üöÄ [AUTO_CREATE] Iniciando auto-cria√ß√£o de sess√£o para team:",
      teamId,
    );

    // 1. Determinar modelo a usar (expl√≠cito ou preferido)
    let preferredModel;
    let aiModelId: string;

    if (input.aiModelId) {
      // ‚úÖ NOVO: Validar modelo expl√≠cito primeiro
      try {
        const explicitModel = await AiStudioService.getModelById({
          modelId: input.aiModelId,
          teamId,
          requestingApp: chatAppId,
        });

        if (explicitModel) {
          preferredModel = explicitModel;
          aiModelId = input.aiModelId;
          console.log(
            "‚úÖ [AUTO_CREATE] Modelo expl√≠cito validado:",
            preferredModel.universalModelId,
          );
        } else {
          throw new Error("Modelo expl√≠cito inv√°lido");
        }
      } catch (error) {
        console.warn(
          "‚ö†Ô∏è [AUTO_CREATE] Modelo expl√≠cito inv√°lido, usando fallback",
        );
        // Fallback para getPreferredModelHelper
        const fallback = await getPreferredModelHelper(teamId, userId);
        preferredModel = fallback.model;
        aiModelId = fallback.modelId;
      }
    } else {
      // Fallback original: buscar modelo preferido
      try {
        const preferredModelResult = await getPreferredModelHelper(
          teamId,
          userId,
        );

        preferredModel = preferredModelResult.model;
        aiModelId = preferredModelResult.modelId;
      } catch (error) {
        console.error(
          "‚ùå [AUTO_CREATE] Erro ao buscar modelo preferido:",
          error,
        );
        throw new TRPCError({
          code: "PRECONDITION_FAILED",
          message:
            "Nenhum modelo de IA dispon√≠vel. Configure modelos no AI Studio.",
        });
      }
    }

    // 2. Gerar t√≠tulo automaticamente (se habilitado)
    let title = "Nova Conversa";

    if (input.generateTitle) {
      try {
        // Buscar token do provider via HTTP
        const providerToken = await AiStudioService.getProviderToken({
          providerId: preferredModel.providerId,
          teamId,
          requestingApp: chatAppId,
        });

        if (providerToken.token) {
          // Configurar API baseada no provider
          const baseUrl =
            preferredModel.provider?.baseUrl || "https://api.openai.com/v1";
          const apiUrl = `${baseUrl}/chat/completions`;

          // Usar configura√ß√µes do modelo
          const modelConfig = (preferredModel.config || {}) as {
            modelId?: string;
            version?: string;
            maxTokens?: number;
            temperature?: number;
          };
          const modelName =
            modelConfig.modelId || modelConfig.version || preferredModel.name;

          // Prompt para gerar t√≠tulo
          const titlePrompt = [
            {
              role: "system",
              content:
                "Voc√™ √© um assistente especializado em criar t√≠tulos concisos. Crie um t√≠tulo curto (m√°ximo 50 caracteres) que capture a ess√™ncia da mensagem do usu√°rio. Responda apenas com o t√≠tulo, sem aspas ou formata√ß√£o adicional.",
            },
            {
              role: "user",
              content: `Crie um t√≠tulo para esta conversa: "${input.firstMessage}"`,
            },
          ];

          const response = await fetch(apiUrl, {
            method: "POST",
            headers: {
              Authorization: `Bearer ${providerToken.token}`,
              "Content-Type": "application/json",
            },
            body: JSON.stringify({
              model: modelName,
              messages: titlePrompt,
              max_tokens: 20,
              temperature: 0.7,
            }),
          });

          if (response.ok) {
            const aiResponse = (await response.json()) as any;
            const generatedTitle =
              aiResponse.choices?.[0]?.message?.content?.trim();

            if (generatedTitle && generatedTitle.length <= 50) {
              title = generatedTitle;
            }
          }
        }
      } catch (error) {
        console.log(
          "‚ö†Ô∏è [AUTO_CREATE] Erro ao gerar t√≠tulo, usando padr√£o:",
          error,
        );
        // Fallback: usar primeiros 50 caracteres da mensagem
        title = input.firstMessage.slice(0, 50);
        if (input.firstMessage.length > 50) {
          title += "...";
        }
      }
    }

    // 3. Criar sess√£o
    const session = await chatRepository.ChatSessionRepository.create({
      title,
      aiModelId,
      teamId,
      userId,
    });

    if (!session?.id) {
      throw new TRPCError({
        code: "INTERNAL_SERVER_ERROR",
        message: "Erro ao criar sess√£o de chat",
      });
    }

    // üéØ NOVO: Criar System Prompt orquestrado (Plataforma + Time)
    try {
      const systemPrompt = await AiStudioService.getSystemPrompt({
        teamId,
        userId,
      });

      if (systemPrompt?.trim()) {
        console.log(
          `üéØ [AUTO_CREATE] Criando System Prompt para sess√£o: ${session.id}`,
        );

        await ChatService.createSystemMessage({
          chatSessionId: session.id,
          content: systemPrompt,
          metadata: {
            type: "system_prompt",
            source: "platform_and_team_instructions",
            createdAt: new Date().toISOString(),
          },
        });

        console.log(
          `‚úÖ [AUTO_CREATE] System Prompt criado para sess√£o: ${session.id}`,
        );
      }
    } catch (error) {
      // Log do erro mas n√£o falha a cria√ß√£o da sess√£o
      console.warn(
        `‚ö†Ô∏è [AUTO_CREATE] Erro ao criar System Prompt para sess√£o ${session.id}:`,
        error,
      );
    }

    // 4. Criar primeira mensagem do usu√°rio
    const userMessage = await chatRepository.ChatMessageRepository.create({
      chatSessionId: session.id,
      senderRole: "user",
      content: input.firstMessage,
      status: "ok",
    });

    // 5. ‚úÖ CORRE√á√ÉO: N√£o processar IA aqui para navega√ß√£o r√°pida
    // A IA ser√° processada via streaming no frontend
    const aiMessage = null;

    return {
      session,
      userMessage,
      aiMessage,
    };
  } catch (error: any) {
    console.error("‚ùå [AUTO_CREATE] Erro:", error);

    if (error instanceof TRPCError) {
      throw error;
    }

    throw new TRPCError({
      code: "INTERNAL_SERVER_ERROR",
      message: error.message || "Erro ao criar sess√£o autom√°tica",
    });
  }
}
