# MigraÃ§Ã£o para Vercel AI SDK - Chat SubApp

## ğŸ¯ VisÃ£o Geral

Este documento detalha a estratÃ©gia de migraÃ§Ã£o do sistema de chat atual para o **Vercel AI SDK**, utilizando uma abordagem de **Adapter Transparente** que preserva 100% das funcionalidades existentes e permite uma transiÃ§Ã£o ultra-segura.

## ğŸ›¡ï¸ EstratÃ©gia: Adapter Transparente (Bridge & Remove)

### Filosofia

- **Preservar 100%** das funcionalidades atuais
- **MigraÃ§Ã£o ultra-segura** sem perda de features
- **Interface externa inalterada** para usuÃ¡rios
- **BenefÃ­cios internos imediatos** do Vercel AI SDK
- **RemoÃ§Ã£o opcional** do adapter no futuro

### Abordagem em Duas Fases

#### ğŸ”„ **Fase 1: Adapter Transparente (ImplementaÃ§Ã£o Segura)**

- Criar camada de adaptaÃ§Ã£o que usa Vercel AI SDK internamente
- Manter interface idÃªntica ao sistema atual
- MigraÃ§Ã£o invisÃ­vel para usuÃ¡rios finais
- PreservaÃ§Ã£o total de funcionalidades

#### ğŸš€ **Fase 2: RemoÃ§Ã£o Opcional (Futuro)**

- Quando confiante, pode remover adapter
- Usar Vercel AI SDK diretamente
- Fase opcional - adapter pode permanecer permanentemente

## ğŸ—ï¸ Arquitetura Proposta

### Sistema Atual

```
Frontend â†’ tRPC â†’ Custom Streaming â†’ OpenAI API â†’ Custom Response Processing
```

### Sistema com Adapter (Fase 1)

```
Frontend â†’ tRPC â†’ Adapter Layer â†’ Vercel AI SDK â†’ Provider APIs â†’ Response Adaptation
```

### Sistema Futuro Opcional (Fase 2)

```
Frontend â†’ tRPC â†’ Vercel AI SDK Direto â†’ Provider APIs
```

## ğŸ“‹ Status da ImplementaÃ§Ã£o

### âœ… **Subetapas ConcluÃ­das:**

1. **âœ… Subetapa 1: Setup e PreparaÃ§Ã£o** - Vercel AI SDK instalado e estrutura criada
2. **âœ… Subetapa 2: Adapter Base** - Adapter skeleton funcionando com mock
3. **âœ… Subetapa 3: IntegraÃ§Ã£o Opcional** - Feature flag, ChatService expandido e endpoint experimental

### ğŸ”„ **PrÃ³ximas Subetapas:**

4. **ğŸ”„ Subetapa 4: ImplementaÃ§Ã£o Real** - Fazer adapter usar Vercel AI SDK de verdade
5. **â³ Subetapa 5: Fallback AutomÃ¡tico** - Sistema de fallback para mÃ¡xima confiabilidade
6. **â³ Subetapa 6: SubstituiÃ§Ã£o Gradual** - MigraÃ§Ã£o opcional do sistema principal

---

## ğŸ“‹ ImplementaÃ§Ã£o Detalhada

### 1. Adapter Principal

```typescript
// packages/api/src/internal/adapters/vercel-ai-adapter.ts

import { anthropic } from "@ai-sdk/anthropic";
import { openai } from "@ai-sdk/openai";
import { generateObject, streamText } from "ai";

import type { ChatStreamParams, ChatStreamResponse } from "../types";

export class VercelAIAdapter {
  /**
   * Adapta streaming atual para usar Vercel AI SDK
   */
  async streamResponse(params: ChatStreamParams): Promise<ChatStreamResponse> {
    // 1. Converter parÃ¢metros para formato Vercel AI SDK
    const vercelParams = this.adaptInputParams(params);

    // 2. Obter modelo configurado
    const model = await this.getVercelModel(params.modelId, params.teamId);

    // 3. Executar streaming com Vercel AI SDK
    const result = await streamText({
      model,
      messages: vercelParams.messages,
      temperature: vercelParams.temperature,
      maxTokens: vercelParams.maxTokens,
      tools: vercelParams.tools, // Nova capacidade!
    });

    // 4. Adaptar resposta para formato atual
    return this.adaptResponse(result);
  }

  /**
   * Converte parÃ¢metros atuais para Vercel AI SDK
   */
  private adaptInputParams(params: ChatStreamParams) {
    return {
      messages: params.messages.map((msg) => ({
        role: msg.senderRole === "user" ? "user" : "assistant",
        content: msg.content,
      })),
      temperature: params.temperature || 0.7,
      maxTokens: params.maxTokens || 4000,
      tools: params.tools || undefined,
    };
  }

  /**
   * Mapeia modelos do AI Studio para Vercel AI SDK
   */
  private async getVercelModel(modelId: string, teamId: string) {
    const modelConfig = await AiStudioService.getModelConfig(modelId, teamId);
    const providerToken = await AiStudioService.getProviderToken(
      modelConfig.providerId,
      teamId,
    );

    switch (modelConfig.provider.name.toLowerCase()) {
      case "openai":
        return openai(modelConfig.name, {
          apiKey: providerToken.token,
          baseURL: modelConfig.provider.baseUrl,
        });

      case "anthropic":
        return anthropic(modelConfig.name, {
          apiKey: providerToken.token,
        });

      // Adicionar outros providers...
      default:
        throw new Error(
          `Provider ${modelConfig.provider.name} not supported yet`,
        );
    }
  }

  /**
   * Adapta resposta do Vercel AI SDK para formato atual
   */
  private adaptResponse(vercelResult: any): ChatStreamResponse {
    // Converter stream do Vercel AI SDK para formato atual
    const stream = new ReadableStream({
      async start(controller) {
        try {
          for await (const chunk of vercelResult.textStream) {
            // Manter formato atual de resposta
            controller.enqueue(new TextEncoder().encode(chunk));
          }
        } finally {
          controller.close();
        }
      },
    });

    return {
      stream,
      metadata: {
        model: vercelResult.response?.modelId,
        usage: vercelResult.usage,
        finishReason: vercelResult.finishReason,
      },
    };
  }
}
```

### 2. IntegraÃ§Ã£o no Service Layer

```typescript
// packages/api/src/internal/services/chat.service.ts

import { VercelAIAdapter } from "../adapters/vercel-ai-adapter";

export class ChatService {
  private static vercelAdapter = new VercelAIAdapter();

  /**
   * Streaming principal - agora usa Vercel AI SDK via adapter
   */
  static async streamResponse(params: ChatStreamParams) {
    try {
      // Usar adapter do Vercel AI SDK
      return await this.vercelAdapter.streamResponse(params);
    } catch (error) {
      console.error(
        "Vercel AI SDK failed, falling back to current system",
        error,
      );

      // Fallback para sistema atual (seguranÃ§a extra)
      return await this.streamResponseCurrent(params);
    }
  }

  /**
   * Sistema atual preservado como fallback
   */
  static async streamResponseCurrent(params: ChatStreamParams) {
    // ImplementaÃ§Ã£o atual mantida intacta
    // ...cÃ³digo atual...
  }
}
```

### 3. Endpoint de API Atualizado

```typescript
// apps/kdx/src/app/api/chat/stream/route.ts

export async function POST(request: NextRequest) {
  try {
    const { chatSessionId, content, modelId } = await request.json();

    // Sistema atual de validaÃ§Ã£o mantido
    const session = await ChatService.findSessionById(chatSessionId);

    // Criar mensagem do usuÃ¡rio (processo atual mantido)
    const userMessage = await ChatService.createMessage({
      chatSessionId: session.id,
      senderRole: "user",
      content,
      status: "ok",
    });

    // MUDANÃ‡A: Usar adapter do Vercel AI SDK
    const streamResponse = await ChatService.streamResponse({
      chatSessionId,
      content,
      modelId: session.aiModelId,
      teamId: session.teamId,
      messages: await ChatService.getSessionMessages(chatSessionId),
    });

    // Resposta no formato atual (unchanged)
    return new Response(streamResponse.stream, {
      headers: {
        "Content-Type": "text/plain; charset=utf-8",
        "Cache-Control": "no-cache",
      },
    });
  } catch (error) {
    // Error handling atual mantido
    console.error("ğŸ”´ [API] Erro no streaming:", error);
    return new Response("Erro de conexÃ£o. Tente novamente.", {
      status: 500,
      headers: { "Content-Type": "text/plain; charset=utf-8" },
    });
  }
}
```

## ğŸ‰ BenefÃ­cios Imediatos

### Para o Sistema

- âœ… **Compatibilidade Universal**: Suporte automÃ¡tico para todos os providers
- âœ… **Tool Calling**: Capacidade de usar ferramentas imediatamente
- âœ… **Structured Objects**: GeraÃ§Ã£o de objetos estruturados
- âœ… **Error Handling**: Sistema robusto de tratamento de erros
- âœ… **Performance**: OtimizaÃ§Ãµes automÃ¡ticas do SDK

### Para Desenvolvedores

- âœ… **CÃ³digo Mais Limpo**: Menos lÃ³gica custom de streaming
- âœ… **ManutenÃ§Ã£o Reduzida**: SDK mantido pela Vercel
- âœ… **Features Futuras**: Updates automÃ¡ticos de capacidades
- âœ… **Debugging**: Ferramentas superiores de debug

### Para UsuÃ¡rios

- âœ… **Zero Impacto**: Interface idÃªntica
- âœ… **Melhor Confiabilidade**: SDK battle-tested
- âœ… **Features Novas**: Tool calling, structured responses
- âœ… **Performance**: Streaming otimizado

## ğŸ“… Cronograma de ImplementaÃ§Ã£o

### **Sprint 1-2: Setup e FundaÃ§Ã£o**

- [ ] Instalar dependÃªncias do Vercel AI SDK
- [ ] Criar estrutura base do adapter
- [ ] Implementar mapeamento bÃ¡sico de providers
- [ ] Testes unitÃ¡rios do adapter

### **Sprint 3-4: ImplementaÃ§Ã£o Core**

- [ ] Adapter completo para OpenAI e Anthropic
- [ ] IntegraÃ§Ã£o com sistema atual de tokens
- [ ] Fallback para sistema atual
- [ ] Testes de integraÃ§Ã£o

### **Sprint 5-6: Deploy e ValidaÃ§Ã£o**

- [ ] Deploy em ambiente de staging
- [ ] Testes extensivos lado-a-lado
- [ ] Monitoramento de performance
- [ ] Ajustes finais

### **Sprint 7-8: ProduÃ§Ã£o**

- [ ] Deploy gradual em produÃ§Ã£o
- [ ] Feature flag para rollback rÃ¡pido
- [ ] Monitoramento intensivo
- [ ] DocumentaÃ§Ã£o final

## ğŸ”¬ Plano de Testes

### Testes de Compatibilidade

```typescript
describe("VercelAIAdapter Compatibility", () => {
  test("should produce identical output to current system", async () => {
    const testParams = {
      /* params padrÃ£o */
    };

    const currentResult = await ChatService.streamResponseCurrent(testParams);
    const adapterResult = await ChatService.streamResponse(testParams);

    expect(adapterResult.format).toEqual(currentResult.format);
    expect(adapterResult.metadata).toMatchStructure(currentResult.metadata);
  });
});
```

### Testes de Performance

- LatÃªncia de primeira resposta
- Throughput de streaming
- Uso de memÃ³ria
- Tempo de conexÃ£o

### Testes de Funcionalidade

- Todos os providers suportados
- Diferentes tipos de mensagem
- Error scenarios
- Fallback automÃ¡tico

## ğŸš¨ Pontos de AtenÃ§Ã£o

### Potenciais Desafios

1. **Mapeamento de ParÃ¢metros**: Cada provider pode ter nuances
2. **Format Differences**: Respostas podem ter formatos ligeiramente diferentes
3. **Error Handling**: Mapear erros do SDK para formato atual
4. **Performance**: Verificar se nÃ£o hÃ¡ degradaÃ§Ã£o

### MitigaÃ§Ãµes

1. **Testes Extensivos**: ValidaÃ§Ã£o lado-a-lado
2. **Fallback AutomÃ¡tico**: Sistema atual como backup
3. **Monitoramento**: MÃ©tricas detalhadas
4. **Feature Flags**: Rollback rÃ¡pido se necessÃ¡rio

## ğŸ”® Futuro: Fase 2 (Opcional)

### Quando Considerar RemoÃ§Ã£o do Adapter

- âœ… Adapter funcionando perfeitamente por 3+ meses
- âœ… Time completamente familiarizado com Vercel AI SDK
- âœ… BenefÃ­cios de performance justificam mudanÃ§a
- âœ… Features especÃ­ficas do SDK sÃ£o necessÃ¡rias

### ImplementaÃ§Ã£o da Fase 2

```typescript
// Futuro: RemoÃ§Ã£o do adapter
export async function POST(request: NextRequest) {
  // Uso direto do Vercel AI SDK
  const result = await streamText({
    model: openai(modelId),
    messages: formattedMessages,
    tools: availableTools, // Features avanÃ§adas
  });

  return result.toDataStreamResponse();
}
```

## ğŸ“Š MÃ©tricas de Sucesso

### KPIs TÃ©cnicos

- **Compatibilidade**: 100% dos casos atuais funcionando
- **Performance**: â‰¤5% diferenÃ§a de latÃªncia
- **Confiabilidade**: <0.1% rate de fallback
- **Coverage**: 100% dos providers migrados

### KPIs de Produto

- **Zero reclamaÃ§Ãµes** de usuÃ¡rios sobre mudanÃ§as
- **Capacidades novas** utilizadas (tool calling, etc.)
- **Tempo de desenvolvimento** reduzido para features futuras
- **Bugs reduzidos** relacionados a streaming

## ğŸ“š Recursos e ReferÃªncias

### DocumentaÃ§Ã£o

- [Vercel AI SDK Docs](https://sdk.vercel.ai/)
- [Streaming Implementation Current](./streaming-implementation.md)
- [Backend Architecture](./backend-architecture.md)

### Code Examples

- [AI SDK Examples](https://github.com/vercel/ai/tree/main/examples)
- [Provider Integrations](https://sdk.vercel.ai/providers)

## ğŸ ConclusÃ£o

Esta estratÃ©gia de **Adapter Transparente** oferece:

âœ… **MigraÃ§Ã£o Ultra-Segura**: Zero risco de perda de funcionalidades
âœ… **BenefÃ­cios Imediatos**: Melhor performance e features novas
âœ… **Flexibilidade Futura**: Pode manter adapter ou remover quando pronto
âœ… **Aprendizado Gradual**: Time aprende SDK sem pressÃ£o

A implementaÃ§Ã£o preserva totalmente o investimento atual enquanto abre portas para capacidades avanÃ§adas do Vercel AI SDK.

---

## ğŸ“ˆ **PROGRESSO DA MIGRAÃ‡ÃƒO**

### âœ… **SUBETAPA 1: Setup e PreparaÃ§Ã£o** - CONCLUÃDA

- âœ… Vercel AI SDK instalado (`ai`, `@ai-sdk/openai`, `@ai-sdk/anthropic`)
- âœ… Estrutura de pastas criada (`adapters/`, `types/ai/`)
- âœ… Tipos TypeScript definidos e compilando
- âœ… Testes de importaÃ§Ã£o passando (3/3)

### âœ… **SUBETAPA 2: Adapter Base** - CONCLUÃDA

- âœ… Adapter skeleton criado e funcionando
- âœ… Stream mock implementado
- âœ… Testes abrangentes (6/6 tests passed)
- âœ… TypeScript compila sem erros
- âœ… Sistema atual 100% preservado

### ğŸ“‹ **PRÃ“XIMAS SUBETAPAS**

- ğŸ”„ **Subetapa 3**: Feature Flag e IntegraÃ§Ã£o Experimental
- ğŸ”„ **Subetapa 4**: ImplementaÃ§Ã£o Real do Vercel AI SDK
- ğŸ”„ **Subetapa 5**: Fallback AutomÃ¡tico
- ğŸ”„ **Subetapa 6**: SubstituiÃ§Ã£o Gradual (Opcional)

---

**Status**: ğŸš§ **Em Progresso** (2/6 subetapas concluÃ­das)  
**Owner**: Time de Desenvolvimento  
**Timeline**: 8 sprints (4 meses)  
**Risk Level**: ğŸŸ¢ **Baixo** (com fallback automÃ¡tico)
