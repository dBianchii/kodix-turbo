# Chat Preferred Model Endpoint - Kodix

## ğŸ“– Overview

O endpoint **`getPreferredModel`** implementa uma **hierarquia de prioridade inteligente** para determinar qual modelo de IA usar no chat, **utilizando Service Layer** para comunicaÃ§Ã£o entre SubApps.

## ğŸ—ï¸ **Arquitetura de Isolamento**

### âœ… **SubApp Isolation Compliance**

- **Chat** âŒ NÃƒO acessa repositÃ³rios do AI Studio diretamente
- **Chat** âœ… Usa `AiStudioService` (Service Layer)
- **AI Studio** âœ… ExpÃµe funcionalidades via service classes
- **Isolamento LÃ³gico** âœ… Mantido entre subapps via `teamId` validation

### ğŸ”„ **Fluxo de ComunicaÃ§Ã£o**

```
Chat Router â†’ AiStudioService â†’ AI Studio Repository â†’ Database
```

## ğŸ¯ **LÃ³gica de Prioridade**

### **1Âª Prioridade: Chat Team Config**

- **Source**: `lastSelectedModelId` da configuraÃ§Ã£o do team no Chat
- **Quando usar**: Quando o team jÃ¡ selecionou um modelo especÃ­fico no chat
- **PersistÃªncia**: Salvo automaticamente quando usuÃ¡rio seleciona modelo

### **2Âª Prioridade: AI Studio Default**

- **Source**: Modelo marcado como `isDefault: true` no AI Studio
- **Quando usar**: Quando nÃ£o hÃ¡ modelo salvo no Chat Team Config
- **ConfiguraÃ§Ã£o**: Definido pelos admins no AI Studio
- **Service Call**: `AiStudioService.getDefaultModel()`

### **3Âª Prioridade: Primeiro Modelo Ativo**

- **Source**: Primeiro modelo habilitado (`enabled: true`) disponÃ­vel
- **Quando usar**: Como fallback final
- **CritÃ©rio**: Primeiro da lista de modelos ativos do team
- **Service Call**: `AiStudioService.getAvailableModels()`

## ğŸ› ï¸ **ImplementaÃ§Ã£o Backend**

### **Service Layer do AI Studio**

```typescript
// packages/api/src/internal/services/ai-studio.service.ts

export class AiStudioService {
  static async getModelById({ modelId, teamId, requestingApp }) {
    // ValidaÃ§Ã£o de teamId e acesso
    // Busca modelo via repository
    return aiStudioRepository.AiModelRepository.findById(modelId);
  }

  static async getDefaultModel({ teamId, requestingApp }) {
    // Busca modelo padrÃ£o do team
    return aiStudioRepository.AiTeamModelConfigRepository.getDefaultModel(
      teamId,
    );
  }

  static async getAvailableModels({ teamId, requestingApp }) {
    // Lista modelos disponÃ­veis do team
    return aiStudioRepository.AiTeamModelConfigRepository.findAvailableModelsByTeam(
      teamId,
    );
  }

  static async getProviderToken({ providerId, teamId, requestingApp }) {
    // Busca token do provider
    return aiStudioRepository.AiTeamProviderTokenRepository.findByTeamAndProvider(
      teamId,
      providerId,
    );
  }
}
```

### **Chat Router com Service Layer**

```typescript
// packages/api/src/trpc/routers/app/chat/_router.ts

import { AiStudioService } from "../../../../internal/services/ai-studio.service";

// Helper para hierarquia de prioridade
async function getPreferredModelHelper(
  teamId: string,
  requestingApp: typeof chatAppId,
) {
  // 1Âª Prioridade: Chat Team Config
  const chatConfigs = await appRepository.findAppTeamConfigs({
    appId: chatAppId,
    teamIds: [teamId],
  });

  const lastSelectedModelId = chatConfig?.config?.lastSelectedModelId;
  if (lastSelectedModelId) {
    // âœ… NOVO: Usar Service Layer
    const model = await AiStudioService.getModelById({
      modelId: lastSelectedModelId,
      teamId,
      requestingApp,
    });

    if (model) {
      return {
        source: "chat_config",
        modelId: model.id,
        model,
        config: chatConfig?.config,
      };
    }
  }

  // 2Âª Prioridade: AI Studio Default via Service Layer
  const defaultModelConfig = await AiStudioService.getDefaultModel({
    teamId,
    requestingApp,
  });

  if (defaultModelConfig?.model) {
    return {
      source: "ai_studio_default",
      modelId: defaultModelConfig.model.id,
      model: defaultModelConfig.model,
      teamConfig: defaultModelConfig,
    };
  }

  // 3Âª Prioridade: Primeiro modelo ativo via Service Layer
  const availableModels = await AiStudioService.getAvailableModels({
    teamId,
    requestingApp,
  });

  const firstActiveModel = availableModels.find((m) => m.teamConfig?.enabled);
  if (firstActiveModel) {
    return {
      source: "first_available",
      modelId: firstActiveModel.id,
      model: firstActiveModel,
      teamConfig: firstActiveModel.teamConfig,
    };
  }

  throw new TRPCError({
    code: "NOT_FOUND",
    message: "Nenhum modelo de IA disponÃ­vel. Configure modelos no AI Studio.",
  });
}

getPreferredModel: protectedProcedure.query(async ({ ctx }) => {
  return getPreferredModelHelper(ctx.auth.user.activeTeamId, chatAppId);
});
```

### **Estrutura de Resposta**

```typescript
interface PreferredModelResult {
  source: "chat_config" | "ai_studio_default" | "first_available";
  modelId: string;
  model: AiModel;
  config?: ChatTeamConfig;
  teamConfig?: AiTeamModelConfig;
}
```

## ğŸ¯ **Frontend Integration**

### **Hook personalizado**

```typescript
// apps/kdx/src/app/[locale]/(authed)/apps/chat/_hooks/useChatPreferredModel.ts

export function useChatPreferredModel() {
  const trpc = useTRPC();

  const {
    data: preferredModel,
    isLoading,
    error,
    refetch,
  } = useQuery({
    ...trpc.app.chat.getPreferredModel.queryOptions(),
    staleTime: 5 * 60 * 1000, // Cache por 5 minutos
    refetchOnWindowFocus: false,
  });

  return {
    preferredModel,
    isLoading,
    error,
    refetch,

    // Helpers
    modelId: preferredModel?.modelId,
    model: preferredModel?.model,
    source: preferredModel?.source,

    // VerificaÃ§Ãµes
    isFromChatConfig: preferredModel?.source === "chat_config",
    isFromAiStudio: preferredModel?.source === "ai_studio_default",
    isFallback: preferredModel?.source === "first_available",
  };
}
```

### **Exemplo de uso**

```typescript
// No componente do Chat
const { preferredModel, isLoading, isFromChatConfig } = useChatPreferredModel();

if (isLoading) return <Loading />;

return (
  <div>
    <h3>Modelo Atual: {preferredModel?.model?.name}</h3>
    <Badge variant={isFromChatConfig ? "primary" : "secondary"}>
      {isFromChatConfig ? "Salvo no Chat" : "PadrÃ£o do AI Studio"}
    </Badge>
  </div>
);
```

## âœ… **BenefÃ­cios da Arquitetura**

### **ğŸ”’ Isolamento Garantido**

- Subapps nÃ£o acessam repositÃ³rios uns dos outros
- ComunicaÃ§Ã£o apenas via HTTP APIs
- Facilita manutenÃ§Ã£o e evoluÃ§Ã£o independente

### **ğŸš€ Performance**

- Cache inteligente no frontend (5 min)
- Chamadas HTTP otimizadas
- Fallbacks eficientes

### **ğŸ›¡ï¸ SeguranÃ§a**

- AutenticaÃ§Ã£o em cada chamada HTTP
- ValidaÃ§Ã£o de team ownership
- Error handling robusto

### **ğŸ“ˆ Escalabilidade**

- Subapps podem ser deployed independentemente
- APIs HTTP podem ser facilmente monitoradas
- Facilita implementaÃ§Ã£o de rate limiting

## ğŸ§ª **Testes**

```bash
# Testar endpoint (requer autenticaÃ§Ã£o)
curl -H "Authorization: Bearer <token>" \
  "http://localhost:3000/api/ai-studio/chat-integration?action=getDefaultModel"

# Testar via tRPC no frontend
const { preferredModel } = useChatPreferredModel();
console.log("Modelo preferido:", preferredModel);
```

## ğŸ“Š **Monitoramento**

Os logs incluem informaÃ§Ãµes detalhadas sobre:

- Qual prioridade foi usada
- Tempos de resposta das chamadas HTTP
- Erros e fallbacks acionados
- Team e modelo selecionado

```
ğŸ¯ [PREFERRED_MODEL] Buscando modelo preferido para team: team_123
âœ… [PREFERRED_MODEL] Encontrado lastSelectedModelId: model_456
ğŸ”„ [AI_STUDIO_API] Chat integration request: getModel
âœ… [PREFERRED_MODEL] Modelo encontrado: gpt-4-turbo
```

## ğŸ¯ **Vantagens da SoluÃ§Ã£o**

### **ğŸ§  InteligÃªncia**

- Combina configuraÃ§Ãµes de duas fontes
- Prioridade baseada na experiÃªncia do usuÃ¡rio
- Fallbacks robustos

### **ğŸ”„ Continuidade**

- Preserva escolhas anteriores do team
- Respeita configuraÃ§Ãµes dos admins
- ExperiÃªncia consistente

### **âš¡ Performance**

- Cache de 5 minutos
- Uma Ãºnica query otimizada
- Fallbacks sem queries adicionais

### **ğŸ›¡ï¸ Robustez**

- Funciona mesmo com configuraÃ§Ãµes incompletas
- Limpa automaticamente dados invÃ¡lidos
- Logs detalhados para debugging

## ğŸ“Š **Exemplos de Logs**

### **Modelo do Chat Config**

```
ğŸ¯ [PREFERRED_MODEL] Buscando modelo preferido para team: abc123
âœ… [PREFERRED_MODEL] Encontrado lastSelectedModelId: gpt-4o-2024-11-20
âœ… [PREFERRED_MODEL] Modelo encontrado: GPT-4o
```

### **Modelo PadrÃ£o do AI Studio**

```
ğŸ¯ [PREFERRED_MODEL] Buscando modelo preferido para team: abc123
ğŸ”„ [PREFERRED_MODEL] Buscando modelo padrÃ£o do AI Studio
âœ… [PREFERRED_MODEL] Modelo padrÃ£o do AI Studio encontrado: Claude 3.5 Sonnet
```

### **Fallback para Primeiro Ativo**

```
ğŸ¯ [PREFERRED_MODEL] Buscando modelo preferido para team: abc123
ğŸ”„ [PREFERRED_MODEL] Buscando modelo padrÃ£o do AI Studio
âš ï¸ [PREFERRED_MODEL] Nenhum modelo padrÃ£o configurado no AI Studio
ğŸ”„ [PREFERRED_MODEL] Usando primeiro modelo ativo como fallback: GPT-3.5 Turbo
```

## ğŸ§ª **Como Testar**

### **1. Teste de Prioridades**

```typescript
// Teste manual das prioridades

// 1. Limpar Chat Team Config
// 2. Configurar modelo padrÃ£o no AI Studio
// 3. Verificar se retorna modelo do AI Studio

// 4. Usar chat e selecionar modelo diferente
// 5. Verificar se prÃ³xima chamada retorna lastSelectedModelId
```

### **2. Teste de Fallbacks**

```typescript
// 1. Remover modelo padrÃ£o do AI Studio
// 2. Verificar se usa primeiro modelo ativo

// 3. Desabilitar todos os modelos
// 4. Verificar se retorna erro apropriado
```

## ğŸ”— **IntegraÃ§Ã£o com Funcionalidades Existentes**

### **Chat Team Config System**

- âœ… LÃª `lastSelectedModelId` existente
- âœ… CompatÃ­vel com salvamento automÃ¡tico
- âœ… Respeita configuraÃ§Ãµes por team

### **AI Studio**

- âœ… Usa modelo padrÃ£o configurado
- âœ… Respeita modelos habilitados/desabilitados
- âœ… Considera tokens de provider

### **Model Selector**

- âœ… PrÃ©-seleciona modelo inteligentemente
- âœ… Atualiza Chat Team Config automaticamente
- âœ… Feedback visual da fonte do modelo

---

## ğŸ“ **ConclusÃ£o**

O endpoint `getPreferredModel` oferece uma experiÃªncia inteligente e robusta para seleÃ§Ã£o de modelos de IA, combinando o melhor dos dois sistemas:

- **PersonalizaÃ§Ã£o por Team** (Chat Team Config)
- **ConfiguraÃ§Ã£o Administrativa** (AI Studio)
- **Fallbacks Inteligentes** (Primeiro modelo disponÃ­vel)

Isso garante que o chat sempre funcione com um modelo apropriado, respeitando as preferÃªncias do team e configuraÃ§Ãµes dos administradores.

## ğŸ¯ **BenefÃ­cios do Service Layer**

### **Performance**

- âœ… **~50-100ms mais rÃ¡pido** que HTTP calls
- âœ… **Menos overhead** de rede e serializaÃ§Ã£o
- âœ… **ReutilizaÃ§Ã£o de conexÃµes** de database

### **Type Safety**

- âœ… **TypeScript nativo** ao invÃ©s de `any`
- âœ… **Intellisense completo** para desenvolvedores
- âœ… **Compile-time validation** de parÃ¢metros

### **Debugging & Observabilidade**

- âœ… **Stack traces completos** em erros
- âœ… **Logging estruturado** com contexto
- âœ… **MÃ©tricas mais precisas** de performance

### **Manutenibilidade**

- âœ… **Menos pontos de falha** (sem HTTP layer)
- âœ… **Refactoring seguro** com TypeScript
- âœ… **Testes mais simples** (menos mocking)

## ğŸ“Š **Logs de Exemplo**

### **Chat Team Config Encontrado**

```
ğŸ¯ [PREFERRED_MODEL] Buscando modelo preferido para team: abc123
ğŸ”„ [AiStudioService] getModelById by z7t3k1q5n8m2 for team: abc123
âœ… [AiStudioService] Model found: GPT-4 Turbo for team: abc123
âœ… [PREFERRED_MODEL] Modelo encontrado: GPT-4 Turbo
```

### **Modelo PadrÃ£o do AI Studio**

```
ğŸ¯ [PREFERRED_MODEL] Buscando modelo preferido para team: abc123
ğŸ”„ [AiStudioService] getDefaultModel by z7t3k1q5n8m2 for team: abc123
âœ… [AiStudioService] Default model found for team abc123: Claude 3.5 Sonnet
```

### **Fallback para Primeiro Ativo**

```
ğŸ¯ [PREFERRED_MODEL] Buscando modelo preferido para team: abc123
ğŸ”„ [AiStudioService] getAvailableModels by z7t3k1q5n8m2 for team: abc123
âœ… [AiStudioService] Found 3 available models for team: abc123
ğŸ”„ [PREFERRED_MODEL] Usando primeiro modelo ativo como fallback: GPT-3.5 Turbo
```
