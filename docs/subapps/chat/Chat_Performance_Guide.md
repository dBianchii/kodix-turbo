# Chat Performance Optimization Guide

## ğŸ“– VisÃ£o Geral

Este guia apresenta estratÃ©gias de otimizaÃ§Ã£o de performance especÃ­ficas para o **Chat SubApp**, incluindo tÃ©cnicas de caching, lazy loading, virtual scrolling e monitoramento de mÃ©tricas crÃ­ticas.

## âš¡ MÃ©tricas de Performance

### **Targets de Performance**

| MÃ©trica                      | Target  | CrÃ­tico |
| ---------------------------- | ------- | ------- |
| **First Contentful Paint**   | < 1.2s  | < 2.0s  |
| **Time to Interactive**      | < 2.5s  | < 4.0s  |
| **Largest Contentful Paint** | < 2.5s  | < 4.0s  |
| **Cumulative Layout Shift**  | < 0.1   | < 0.25  |
| **First Input Delay**        | < 100ms | < 300ms |

### **Chat-Specific Metrics**

| Funcionalidade          | Target        | DescriÃ§Ã£o                            |
| ----------------------- | ------------- | ------------------------------------ |
| **Message Render Time** | < 50ms        | Tempo para renderizar nova mensagem  |
| **Streaming Speed**     | 20-30 chars/s | Velocidade do efeito de digitaÃ§Ã£o    |
| **Session Load**        | < 500ms       | Tempo para carregar sessÃ£o existente |
| **Model Switch**        | < 200ms       | Tempo para trocar modelo             |

## ğŸ¯ OtimizaÃ§Ãµes Implementadas

### **1. React Query Caching**

#### **Cache Strategy**

```typescript
// ConfiguraÃ§Ã£o otimizada de cache
const queryClient = new QueryClient({
  defaultOptions: {
    queries: {
      // Chat sessions - cache por 10 minutos
      staleTime: 10 * 60 * 1000,
      gcTime: 30 * 60 * 1000,
      refetchOnWindowFocus: false,
      refetchOnReconnect: "always",
    },
  },
});

// Cache especÃ­fico por tipo de dados
const chatQueries = {
  sessions: {
    staleTime: 10 * 60 * 1000, // Sessions mudam pouco
    gcTime: 30 * 60 * 1000,
  },
  messages: {
    staleTime: 5 * 60 * 1000, // Messages podem ser mais frequentes
    gcTime: 15 * 60 * 1000,
  },
  models: {
    staleTime: 60 * 60 * 1000, // Models raramente mudam
    gcTime: 2 * 60 * 60 * 1000,
  },
};
```

#### **InvalidaÃ§Ã£o Inteligente**

```typescript
// âœ… InvalidaÃ§Ã£o granular - sÃ³ o necessÃ¡rio
const handleSendMessage = useMutation({
  mutationFn: sendMessage,
  onSuccess: (data, variables) => {
    // Invalida apenas mensagens da sessÃ£o especÃ­fica
    queryClient.invalidateQueries({
      queryKey: ["chat", "messages", variables.sessionId],
    });

    // NÃ£o invalida outras sessÃµes ou modelos
    // Atualiza lastActivity da sessÃ£o sem invalidar lista completa
    queryClient.setQueryData(["chat", "sessions"], (oldData: ChatSession[]) =>
      oldData?.map((session) =>
        session.id === variables.sessionId
          ? { ...session, lastActivity: new Date() }
          : session,
      ),
    );
  },
});

// âŒ EVITAR - InvalidaÃ§Ã£o ampla demais
queryClient.invalidateQueries(["chat"]); // Invalida TUDO
```

### **2. Component Memoization**

#### **Message Component Optimization**

```typescript
// âœ… MemoizaÃ§Ã£o otimizada
const Message = memo(({
  message,
  isNewMessage,
  onTypingComplete
}: MessageProps) => {
  // SÃ³ renderiza novamente se props essenciais mudaram
  return (
    <div className="message-container">
      <MessageContent content={message.content} />
      {isNewMessage && (
        <TypingEffect
          text={message.content}
          onComplete={onTypingComplete}
        />
      )}
    </div>
  );
}, (prevProps, nextProps) => {
  // Custom comparison para otimizar
  return (
    prevProps.message.id === nextProps.message.id &&
    prevProps.message.content === nextProps.message.content &&
    prevProps.isNewMessage === nextProps.isNewMessage
  );
});

// âœ… Callback memoization
const ChatWindow = ({ sessionId }: ChatWindowProps) => {
  const handleTypingComplete = useCallback((messageId: string) => {
    setMessages(prev =>
      prev.map(msg =>
        msg.id === messageId
          ? { ...msg, isNewMessage: false }
          : msg
      )
    );
  }, []);

  // Evita re-render desnecessÃ¡rio de Message components
  return (
    <div>
      {messages.map(msg => (
        <Message
          key={msg.id}
          message={msg}
          isNewMessage={msg.isNewMessage}
          onTypingComplete={handleTypingComplete}
        />
      ))}
    </div>
  );
};
```

### **3. Virtual Scrolling (Futuro)**

#### **ImplementaÃ§Ã£o Planejada**

```typescript
// Para implementar quando sessÃµes tiverem 500+ mensagens
import { FixedSizeList as List } from 'react-window';

const VirtualChatWindow = ({ messages }: Props) => {
  const listRef = useRef<List>(null);

  // Scroll automÃ¡tico para nova mensagem
  useEffect(() => {
    if (messages.length > 0) {
      listRef.current?.scrollToItem(messages.length - 1);
    }
  }, [messages.length]);

  const renderMessage = useCallback(({ index, style }: ListChildComponentProps) => (
    <div style={style}>
      <Message message={messages[index]} />
    </div>
  ), [messages]);

  return (
    <List
      ref={listRef}
      height={600}
      itemCount={messages.length}
      itemSize={80} // Altura estimada da mensagem
      itemData={messages}
    >
      {renderMessage}
    </List>
  );
};
```

### **4. Lazy Loading Components**

#### **Code Splitting**

```typescript
// âœ… Lazy loading de componentes pesados
const ModelSelector = lazy(() =>
  import('../components/model-selector').then(module => ({
    default: module.ModelSelector
  }))
);

const SessionEditModal = lazy(() =>
  import('../components/session-edit-modal')
);

// âœ… Uso com Suspense
const ChatPage = () => (
  <div>
    <Suspense fallback={<ModelSelectorSkeleton />}>
      <ModelSelector />
    </Suspense>

    <Suspense fallback={<div>Carregando editor...</div>}>
      {showEditModal && <SessionEditModal />}
    </Suspense>
  </div>
);
```

#### **Dynamic Imports**

```typescript
// âœ… Import dinÃ¢mico baseado em condiÃ§Ãµes
const loadAdvancedFeatures = async () => {
  if (user.plan === "premium") {
    const { AdvancedChatFeatures } = await import("./advanced-features");
    return AdvancedChatFeatures;
  }
  return null;
};

// âœ… Lazy loading de utilidades pesadas
const processLargeFile = async (file: File) => {
  const { processFile } = await import("./file-processor");
  return processFile(file);
};
```

### **5. Image and Asset Optimization**

```typescript
// âœ… Next.js Image com otimizaÃ§Ã£o
import Image from 'next/image';

const Avatar = ({ src, alt }: AvatarProps) => (
  <Image
    src={src}
    alt={alt}
    width={40}
    height={40}
    className="rounded-full"
    priority={false} // NÃ£o Ã© critical
    loading="lazy"
    placeholder="blur"
    blurDataURL="data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQ..." // Base64 pequeno
  />
);

// âœ… Preload de recursos crÃ­ticos
const preloadCriticalAssets = () => {
  // Preload de fontes importantes
  const link = document.createElement('link');
  link.rel = 'preload';
  link.href = '/fonts/inter-var.woff2';
  link.as = 'font';
  link.type = 'font/woff2';
  link.crossOrigin = 'anonymous';
  document.head.appendChild(link);
};
```

## ğŸ£ Hooks Otimizados

### **useChatPreferredModel Optimization**

```typescript
const useChatPreferredModel = () => {
  // âœ… Cache com duraÃ§Ã£o mais longa para dados estÃ¡veis
  const { data: chatConfig } = useChatConfig({
    staleTime: 15 * 60 * 1000, // 15 minutos
    gcTime: 30 * 60 * 1000,
  });

  const { data: defaultModel } = api.aiStudio.getDefaultModel.useQuery(
    undefined,
    {
      enabled: !chatConfig?.lastSelectedModelId,
      staleTime: 60 * 60 * 1000, // 1 hora - raramente muda
      gcTime: 2 * 60 * 60 * 1000,
    },
  );

  // âœ… MemoizaÃ§Ã£o do resultado final
  return useMemo(() => {
    if (chatConfig?.lastSelectedModelId) {
      return {
        modelId: chatConfig.lastSelectedModelId,
        source: "chat_config" as const,
        isReady: true,
      };
    }

    if (defaultModel) {
      return {
        modelId: defaultModel.id,
        source: "ai_studio_default" as const,
        isReady: true,
      };
    }

    return {
      modelId: null,
      source: null,
      isReady: false,
    };
  }, [chatConfig?.lastSelectedModelId, defaultModel]);
};
```

### **useAutoCreateSession Debouncing**

```typescript
const useAutoCreateSession = ({ onSessionCreated }: Props) => {
  // âœ… Debounce para evitar mÃºltiplas criaÃ§Ãµes
  const debouncedCreateSession = useMemo(
    () =>
      debounce(async (params: CreateSessionParams) => {
        const session = await createSessionMutation.mutateAsync(params);
        onSessionCreated(session.id);
        return session;
      }, 300),
    [createSessionMutation, onSessionCreated],
  );

  const createSessionAndSendMessage = useCallback(
    async (params: SendMessageParams) => {
      // Evita race conditions
      if (createSessionMutation.isPending) {
        return;
      }

      const session = await debouncedCreateSession({
        title: generateTitle(params.content),
        aiModelId: params.modelId,
        chatFolderId: params.folderId,
      });

      // Enviar mensagem imediatamente apÃ³s criaÃ§Ã£o
      await sendMessageMutation.mutateAsync({
        sessionId: session.id,
        content: params.content,
        role: "user",
      });
    },
    [debouncedCreateSession, sendMessageMutation],
  );

  return { createSessionAndSendMessage };
};
```

## ğŸ“Š Bundle Optimization

### **Webpack Analysis**

```bash
# Analisar bundle do Chat
pnpm build
pnpm analyze

# Comando para anÃ¡lise especÃ­fica
ANALYZE=true pnpm build
```

### **Bundle Splitting Strategy**

```typescript
// next.config.js
module.exports = {
  experimental: {
    optimizePackageImports: [
      "@radix-ui/react-dialog",
      "@radix-ui/react-dropdown-menu",
      "lucide-react",
    ],
  },

  webpack: (config) => {
    // Split vendors importantes
    config.optimization.splitChunks.cacheGroups = {
      ...config.optimization.splitChunks.cacheGroups,

      // Chunk especÃ­fico para AI libraries
      aiLibs: {
        test: /[\\/]node_modules[\\/](openai|anthropic|google-ai)[\\/]/,
        name: "ai-libs",
        chunks: "all",
        priority: 20,
      },

      // Chunk para UI components
      uiComponents: {
        test: /[\\/]node_modules[\\/](@radix-ui|lucide-react)[\\/]/,
        name: "ui-components",
        chunks: "all",
        priority: 15,
      },
    };

    return config;
  },
};
```

## ğŸ” Performance Monitoring

### **Core Web Vitals Tracking**

```typescript
// utils/performance-tracker.ts
export const trackChatPerformance = () => {
  // Track custom metrics
  const observer = new PerformanceObserver((list) => {
    for (const entry of list.getEntries()) {
      if (entry.name === 'chat-message-render') {
        // Track message render time
        analytics.track('chat_message_render_time', {
          duration: entry.duration,
          entryType: entry.entryType,
        });
      }
    }
  });

  observer.observe({ entryTypes: ['measure'] });

  // Track streaming speed
  const trackStreamingSpeed = (messageLength: number, duration: number) => {
    const charsPerSecond = messageLength / (duration / 1000);
    analytics.track('chat_streaming_speed', {
      chars_per_second: charsPerSecond,
      message_length: messageLength,
      duration_ms: duration,
    });
  };

  return { trackStreamingSpeed };
};

// Component usage
const Message = ({ content, isNewMessage }: MessageProps) => {
  useEffect(() => {
    if (isNewMessage) {
      performance.mark('message-render-start');
    }
  }, [isNewMessage]);

  const handleTypingComplete = useCallback(() => {
    performance.mark('message-render-end');
    performance.measure(
      'chat-message-render',
      'message-render-start',
      'message-render-end'
    );
  }, []);

  return (
    <TypingEffect
      text={content}
      onComplete={handleTypingComplete}
    />
  );
};
```

### **Real User Monitoring (RUM)**

```typescript
// hooks/usePerformanceMonitoring.ts
export const usePerformanceMonitoring = () => {
  useEffect(() => {
    // Monitor navigation timing
    const navigationEntry = performance.getEntriesByType(
      "navigation",
    )[0] as PerformanceNavigationTiming;

    const metrics = {
      dns_lookup:
        navigationEntry.domainLookupEnd - navigationEntry.domainLookupStart,
      tcp_connect: navigationEntry.connectEnd - navigationEntry.connectStart,
      request_time: navigationEntry.responseEnd - navigationEntry.requestStart,
      dom_interactive:
        navigationEntry.domInteractive - navigationEntry.navigationStart,
      dom_complete:
        navigationEntry.domComplete - navigationEntry.navigationStart,
    };

    // Send to analytics
    analytics.track("chat_page_performance", metrics);

    // Monitor LCP for chat messages
    const lcpObserver = new PerformanceObserver((list) => {
      const entries = list.getEntries();
      const lastEntry = entries[entries.length - 1];

      analytics.track("chat_lcp", {
        value: lastEntry.startTime,
        url: window.location.pathname,
      });
    });

    lcpObserver.observe({ type: "largest-contentful-paint", buffered: true });

    return () => lcpObserver.disconnect();
  }, []);
};
```

## ğŸ› ï¸ Development Tools

### **Performance Profiling**

```typescript
// utils/dev-performance.ts
export const profileChatComponent = (componentName: string) => {
  if (process.env.NODE_ENV !== "development") return;

  const start = performance.now();

  return {
    end: () => {
      const duration = performance.now() - start;
      console.log(`ğŸ” ${componentName} render time: ${duration.toFixed(2)}ms`);

      if (duration > 16.67) {
        // > 1 frame at 60fps
        console.warn(`âš ï¸ ${componentName} slow render detected`);
      }
    },
  };
};

// Usage in components
const ChatWindow = () => {
  const profiler = profileChatComponent("ChatWindow");

  useEffect(() => {
    profiler?.end();
  });

  // ... component logic
};
```

### **Bundle Analysis Commands**

```bash
# Analisar tamanho especÃ­fico do Chat
npx next-bundle-analyzer

# Ver dependÃªncias do Chat
pnpm why react-query
pnpm why @tanstack/react-query

# Verificar duplicaÃ§Ãµes
npx duplicate-package-checker-webpack-plugin

# Performance audit
npx lighthouse http://localhost:3000/apps/chat --output html --output-path ./chat-lighthouse.html
```

## ğŸ“ˆ Optimization Roadmap

### **Fase 1: Implementado âœ…**

- [x] React Query caching otimizado
- [x] Component memoization
- [x] Code splitting bÃ¡sico
- [x] Image optimization
- [x] Performance monitoring bÃ¡sico

### **Fase 2: Em Desenvolvimento ğŸš§**

- [ ] Virtual scrolling para mensagens longas
- [ ] Service Worker para cache offline
- [ ] Preloading inteligente de sessÃµes
- [ ] Streaming otimizado com Web Workers

### **Fase 3: Planejado ğŸ“‹**

- [ ] Edge caching com Vercel Edge Functions
- [ ] Database query optimization
- [ ] CDN optimization para assets
- [ ] Advanced prefetching strategies

### **MÃ©tricas de Sucesso**

| MÃ©trica            | Antes | Meta    | Status |
| ------------------ | ----- | ------- | ------ |
| **Bundle Size**    | 1.2MB | < 800KB | ğŸš§     |
| **TTI**            | 3.2s  | < 2.5s  | âœ…     |
| **Message Render** | 80ms  | < 50ms  | âœ…     |
| **Cache Hit Rate** | 65%   | > 85%   | ğŸš§     |

## ğŸ”§ Troubleshooting Performance

### **Common Issues**

#### **Slow Message Rendering**

```typescript
// âŒ Problema comum
const ChatWindow = () => {
  const [messages, setMessages] = useState([]);

  // Re-render toda vez que qualquer mensagem muda
  return (
    <div>
      {messages.map(msg => (
        <Message key={msg.id} message={msg} /> // Sem memoization
      ))}
    </div>
  );
};

// âœ… SoluÃ§Ã£o
const ChatWindow = () => {
  const [messages, setMessages] = useState([]);

  const memoizedMessages = useMemo(() => messages, [messages]);

  return (
    <div>
      {memoizedMessages.map(msg => (
        <MemoizedMessage key={msg.id} message={msg} />
      ))}
    </div>
  );
};
```

#### **Memory Leaks**

```typescript
// âŒ Memory leak comum
const useTypingEffect = (text: string) => {
  useEffect(() => {
    const interval = setInterval(() => {
      // Atualiza estado sem cleanup
    }, 50);

    // âŒ NÃ£o limpa interval
  }, [text]);
};

// âœ… Cleanup correto
const useTypingEffect = (text: string) => {
  useEffect(() => {
    const interval = setInterval(() => {
      // Atualiza estado
    }, 50);

    return () => clearInterval(interval); // âœ… Cleanup
  }, [text]);
};
```

### **Performance Debugging Tools**

```typescript
// Debug queries lentas
const debugSlowQueries = () => {
  if (process.env.NODE_ENV === "development") {
    const originalQuery = queryClient.getQueryCache();

    // Log queries que demoram mais de 1s
    originalQuery.subscribe((event) => {
      if (
        event.type === "updated" &&
        event.query.state.fetchStatus === "fetching"
      ) {
        const start = Date.now();

        event.query.promise?.finally(() => {
          const duration = Date.now() - start;
          if (duration > 1000) {
            console.warn(`ğŸŒ Slow query detected:`, {
              queryKey: event.query.queryKey,
              duration: `${duration}ms`,
            });
          }
        });
      }
    });
  }
};
```

---

## ğŸ“š Recursos Relacionados

- **[Chat Development Guide](./Chat_Development_Guide.md)** - PadrÃµes de desenvolvimento
- **[Performance Best Practices](../../architecture/performance-guide.md)** - PadrÃµes gerais
- **[React Query Performance](https://tanstack.com/query/v4/docs/guides/performance)** - DocumentaÃ§Ã£o oficial
- **[Next.js Performance](https://nextjs.org/docs/advanced-features/measuring-performance)** - Guia oficial

---

**ğŸ“ Ãšltima atualizaÃ§Ã£o**: Janeiro 2025 | **âš¡ Stack**: Next.js 14 + React Query | **ğŸ¯ Target**: < 2.5s TTI
