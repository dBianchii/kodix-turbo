# Known Issues - Chat SubApp

## ‚ö†Ô∏è Problemas Conhecidos

Este documento lista os problemas conhecidos do Chat e suas solu√ß√µes tempor√°rias. O sistema utiliza arquitetura h√≠brida (Vercel AI SDK + Legacy fallback).

## üî¥ Problemas Cr√≠ticos

### 1. Limite de Tokens Excedido

**Sintoma**: Erro "max_tokens: X > Y" ao usar certos modelos.

**Causa**: Contexto da conversa excede limites configurados no AI Studio.

**Workaround**:

- Reduzir o hist√≥rico da conversa
- Criar nova sess√£o para t√≥pico diferente
- Verificar limites no AI Studio > Modelos

**Status**: Em desenvolvimento - sistema de truncamento autom√°tico.

### 2. Perda de Contexto em Conversas Longas

**Sintoma**: IA "esquece" informa√ß√µes mencionadas anteriormente.

**Causa**: Sistema trunca mensagens antigas para caber no limite de tokens.

**Workaround**:

- Criar nova sess√£o para t√≥picos diferentes
- Resumir pontos importantes periodicamente
- Verificar modelos com limites maiores no AI Studio

**Status**: Planejado - sistema de resumo autom√°tico.

## üü° Problemas Moderados

### 3. Sess√£o Sem Modelo Configurado

**Sintoma**: Chat usa modelo padr√£o mesmo ap√≥s selecionar outro.

**Causa**: Sess√£o criada antes da sele√ß√£o do modelo.

**Workaround**:

- Selecionar modelo antes de enviar primeira mensagem
- Atualizar sess√£o manualmente ap√≥s cria√ß√£o

**Status**: Parcialmente resolvido - fallback autom√°tico implementado.

### 4. Streaming Interrompido

**Sintoma**: Resposta para no meio da gera√ß√£o.

**Causa**: Timeout de conex√£o ou erro no provider.

**Workaround**:

- Reenviar a mensagem
- Verificar status do provider no AI Studio
- Reduzir tamanho da resposta esperada

**Status**: Em investiga√ß√£o.

### 5. Hist√≥rico N√£o Carrega

**Sintoma**: Mensagens antigas n√£o aparecem ao reabrir sess√£o.

**Causa**: Pagina√ß√£o n√£o implementada completamente.

**Workaround**:

- Scroll manual para carregar mais mensagens
- Limite atual de 20 mensagens por p√°gina

**Status**: Feature em desenvolvimento.

## üîß Problemas do Sistema H√≠brido

### 6. Fallback Frequente para Sistema Legacy

**Sintoma**: Sistema usa legacy mesmo com Vercel AI SDK habilitado.

**Causa**: Erros no Vercel AI SDK causam fallback autom√°tico.

**Diagn√≥stico**:

```bash
# Verificar taxa de fallback
grep -c "fallback para sistema atual" logs/app.log

# Verificar erros do Vercel AI SDK
grep "üî¥ \[MIGRATION\]" logs/app.log
```

**Workaround**:

- Verificar configura√ß√£o de tokens no AI Studio
- Confirmar que modelos est√£o ativos
- Verificar conectividade com providers

**Status**: Monitoramento ativo - fallback √© comportamento esperado.

### 7. Headers Inconsistentes

**Sintoma**: Header `X-Powered-By` aparece/desaparece entre requisi√ß√µes.

**Causa**: Sistema h√≠brido alterna entre Vercel AI SDK e Legacy.

**Identifica√ß√£o**:

```bash
# Verificar qual sistema est√° ativo
curl -I http://localhost:3000/api/chat/stream | grep "X-Powered-By"

# Vercel AI SDK ativo: X-Powered-By: Vercel-AI-SDK
# Legacy ativo: (sem header)
```

**Status**: Comportamento esperado do sistema h√≠brido.

### 8. Feature Flag N√£o Funciona

**Sintoma**: `ENABLE_VERCEL_AI_ADAPTER=false` n√£o desabilita Vercel AI SDK.

**Causa**: Vari√°vel de ambiente n√£o carregada ou servidor n√£o reiniciado.

**Solu√ß√£o**:

```bash
# Verificar vari√°vel
echo $ENABLE_VERCEL_AI_ADAPTER

# Reiniciar servidor
pnpm dev:kdx
```

**Status**: Configura√ß√£o - n√£o √© bug.

## üü¢ Problemas Menores

### 9. T√≠tulo Autom√°tico Gen√©rico

**Sintoma**: Sess√µes criadas com t√≠tulos como "Nova Conversa".

**Causa**: Gera√ß√£o de t√≠tulo baseada em primeira mensagem n√£o implementada.

**Workaround**:

- Editar t√≠tulo manualmente ap√≥s cria√ß√£o
- Incluir contexto claro na primeira mensagem

**Status**: Feature planejada.

### 10. Markdown Parcial

**Sintoma**: Alguns elementos markdown n√£o s√£o renderizados.

**Causa**: Parser markdown limitado.

**Workaround**:

- Usar formata√ß√£o b√°sica (negrito, it√°lico, listas)
- Evitar tabelas complexas e blocos de c√≥digo aninhados

**Status**: Melhoria planejada.

### 11. Mobile: Teclado Cobre Input

**Sintoma**: Em alguns dispositivos m√≥veis, o teclado cobre o campo de input.

**Causa**: Viewport n√£o ajusta corretamente.

**Workaround**:

- Rolar manualmente para ver o input
- Usar em modo landscape

**Status**: Fix em desenvolvimento.

## üîß Problemas de Integra√ß√£o

### 12. Token Expirado do Provider

**Sintoma**: Erro 401 ao enviar mensagem.

**Causa**: Token da API do provider expirou ou √© inv√°lido.

**Solu√ß√£o**:

1. Acessar AI Studio > Tokens
2. Atualizar token do provider afetado
3. Verificar se modelo est√° ativo

**Status**: Melhorias na UX de erro planejadas.

### 13. Modelo N√£o Dispon√≠vel

**Sintoma**: Modelo selecionado n√£o funciona.

**Causa**: Modelo foi desativado no AI Studio ou requer configura√ß√£o adicional.

**Solu√ß√£o**:

1. Verificar status no AI Studio > Modelos
2. Confirmar que o provedor tem token v√°lido
3. Selecionar modelo alternativo ativo

**Status**: Valida√ß√£o em tempo real planejada.

### 14. Provider N√£o Suportado pelo Vercel AI SDK

**Sintoma**: Erro "Provider X not supported" mesmo com token v√°lido.

**Causa**: Vercel AI SDK ainda n√£o suporta o provider, sistema usa legacy automaticamente.

**Identifica√ß√£o**:

```bash
# Verificar logs de provider
grep "Provider.*not supported" logs/app.log
```

**Status**: Comportamento esperado - fallback autom√°tico funciona.

## üìä Problemas de Performance

### 15. Lentid√£o com Muitas Sess√µes

**Sintoma**: Interface fica lenta com 50+ sess√µes.

**Causa**: Todas as sess√µes s√£o carregadas de uma vez.

**Workaround**:

- Deletar sess√µes antigas
- Usar busca para filtrar

**Status**: Virtualiza√ß√£o da lista planejada.

### 16. Delay no Primeiro Token

**Sintoma**: Demora para come√ßar a mostrar resposta.

**Causa**: Lat√™ncia do provider + processamento.

**Workaround**:

- Usar modelos mais r√°pidos (GPT-3.5)
- Verificar conex√£o de internet

**Status**: Otimiza√ß√µes em andamento.

### 17. Diferen√ßa de Performance Entre Sistemas

**Sintoma**: Vercel AI SDK √†s vezes mais lento que sistema legacy.

**Causa**: Overhead da camada de adapta√ß√£o.

**Monitoramento**:

```bash
# Comparar tempos de resposta
grep -E "POST.*stream.*in.*ms" logs/app.log
```

**Status**: Otimiza√ß√£o do adapter em andamento.

## üîç Debugging do Sistema H√≠brido

### Comandos √öteis

```bash
# Verificar qual sistema est√° ativo
grep -E "\[MIGRATION\]|\[LEGACY\]" logs/app.log | tail -10

# Verificar taxa de fallback
grep -c "fallback para sistema atual" logs/app.log

# Verificar feature flag
grep "VERCEL_AI_ADAPTER" logs/app.log | tail -5

# Status geral
curl -s -I http://localhost:3000/api/chat/stream | grep -E "HTTP|X-Powered-By"
```

### Identifica√ß√£o de Problemas

1. **Sistema sempre usa Legacy**: Verificar feature flag
2. **Fallbacks frequentes**: Verificar tokens e modelos
3. **Performance degradada**: Comparar sistemas via logs
4. **Erros de provider**: Verificar configura√ß√£o no AI Studio

## üêõ Como Reportar Novos Problemas

### Informa√ß√µes Necess√°rias

1. **Descri√ß√£o clara** do problema
2. **Sistema ativo** (Vercel AI SDK ou Legacy)
3. **Passos para reproduzir**
4. **Logs relevantes** (incluir `[MIGRATION]` ou `[LEGACY]`)
5. **Headers HTTP** se aplic√°vel
6. **Feature flag status**: `ENABLE_VERCEL_AI_ADAPTER`
7. **Modelo de IA** sendo usado
8. **Navegador e OS**

### Onde Reportar

- Issues do GitHub do projeto
- Canal #bugs no Slack/Discord da equipe
- Email: support@kodix.com

## üîÑ Atualiza√ß√µes

**√öltima atualiza√ß√£o**: Janeiro 2024

**Frequ√™ncia de revis√£o**: Mensal

**Pr√≥xima revis√£o**: Fevereiro 2024

## üìù Notas

- Problemas marcados como "Em desenvolvimento" t√™m PRs abertas
- Problemas "Planejados" est√£o no roadmap do pr√≥ximo quarter
- Workarounds s√£o solu√ß√µes tempor√°rias at√© fix definitivo
- **Sistema h√≠brido**: Fallbacks s√£o comportamento esperado, n√£o bugs

---

**üéâ Sistema h√≠brido robusto: Vercel AI SDK como principal + Fallback autom√°tico para m√°xima confiabilidade!**
