# Chat SubApp

## ğŸ“– VisÃ£o Geral

O **Chat** Ã© o sistema de conversaÃ§Ã£o inteligente do Kodix que permite interaÃ§Ãµes em tempo real com modelos de IA. Utiliza exclusivamente o **Vercel AI SDK** como engine de IA, consumindo recursos gerenciados pelo AI Studio de forma moderna e otimizada.

## ğŸš€ InÃ­cio RÃ¡pido

### 1. Executar o Projeto

```bash
# Executar todo o monorepo
pnpm dev:kdx
```

### 2. Configurar AI Studio (PrÃ©-requisito)

âš ï¸ **Antes de usar o Chat, configure o AI Studio:**

1. Acesse `/apps/aiStudio`
2. Configure provedores e tokens
3. Ative modelos desejados
4. Crie agentes (opcional)

### 3. Acessar o Chat

1. FaÃ§a login na aplicaÃ§Ã£o
2. Navegue para `/apps/chat`
3. O sistema criarÃ¡ automaticamente uma nova sessÃ£o ao enviar a primeira mensagem
4. Selecione um modelo disponÃ­vel ou use o padrÃ£o do time

## ğŸ”§ Funcionalidades Principais

### ConversaÃ§Ã£o em Tempo Real

- **Streaming de Respostas**: Respostas fluidas com texto aparecendo progressivamente
- **Vercel AI SDK**: Sistema moderno de IA como engine Ãºnica
- **Auto-Save Inteligente**: Mensagens salvas automaticamente durante o streaming
- **HistÃ³rico Persistente**: Todas as conversas sÃ£o salvas e organizadas por sessÃ£o
- **Contexto Mantido**: O chat mantÃ©m o contexto completo da conversa
- **Markdown Support**: RenderizaÃ§Ã£o de cÃ³digo, listas e formataÃ§Ã£o
- **Auto-Focus Inteligente**: Cursor retorna automaticamente ao input apÃ³s streaming
- **Token Usage Visibility**: Badge interativo mostrando uso de tokens em tempo real

### GestÃ£o de SessÃµes

- **MÃºltiplas Conversas**: Organize diferentes tÃ³picos em sessÃµes separadas
- **TÃ­tulos AutomÃ¡ticos**: GeraÃ§Ã£o inteligente de tÃ­tulos baseada no conteÃºdo
- **Busca e Filtros**: Encontre rapidamente conversas anteriores
- **Auto-criaÃ§Ã£o**: Primeira mensagem cria sessÃ£o automaticamente

### SeleÃ§Ã£o de Modelos

- **Modelos DisponÃ­veis**: Usa modelos configurados no AI Studio
- **Troca DinÃ¢mica**: Mude de modelo durante a conversa
- **Fallback Inteligente**: SeleÃ§Ã£o automÃ¡tica se modelo nÃ£o especificado
- **PersistÃªncia**: Modelo selecionado Ã© salvo na sessÃ£o

### Interface Intuitiva

- **Design Responsivo**: Funciona perfeitamente em desktop e mobile
- **Tema Escuro**: Interface moderna com tema escuro por padrÃ£o
- **Atalhos de Teclado**: NavegaÃ§Ã£o rÃ¡pida e eficiente
- **Sidebar ColapsÃ¡vel**: Lista de sessÃµes sempre acessÃ­vel
- **Token Usage Badge**: Popover detalhado com informaÃ§Ãµes de consumo de tokens
- **Interface Limpa**: TÃ­tulo "Chat" removido para design mais minimalista
- **Auto-Focus**: Input focado automaticamente apÃ³s resposta da IA

### Tecnologia AvanÃ§ada

- **Vercel AI SDK**: Engine Ãºnica com suporte otimizado a mÃºltiplos providers
- **Multi-Provider**: Suporte nativo a OpenAI, Anthropic via Vercel AI SDK
- **Stream + Auto-Save**: Streaming e persistÃªncia integrados
- **Monitoramento**: Logs detalhados para observabilidade
- **Interface Ultra-Limpa**: Complexidade encapsulada no backend

## ğŸ—ï¸ Arquitetura Atual

### Sistema 100% Nativo

```
Frontend â†’ tRPC â†’ Vercel AI SDK (Native) â†’ Provider APIs â†’ Auto-Save (onFinish)
```

### IdentificaÃ§Ã£o do Sistema

- **Header HTTP**: `X-Powered-By: Vercel-AI-SDK-Native`
- **Logs**: `ğŸš€ [VERCEL_AI_NATIVE]` para todas as operaÃ§Ãµes
- **Metadata**: Mensagens marcadas com `providerId: "vercel-ai-sdk-native"`

### Fluxo de Processamento

1. **RequisiÃ§Ã£o** chega no endpoint `/api/chat/stream`
2. **streamText()** nativo do Vercel AI SDK
3. **Streaming** via `toDataStreamResponse()` padrÃ£o
4. **Auto-Save** via callback `onFinish` nativo
5. **Error Handling** via callback `onError` nativo

## ğŸ“š DocumentaÃ§Ã£o Completa

### **Arquitetura e ImplementaÃ§Ã£o**

- **[ğŸ“± Frontend Architecture](./frontend-architecture.md)** - Estrutura e componentes da interface
- **[âš™ï¸ Backend Architecture](./backend-architecture.md)** - APIs e processamento server-side
- **[ğŸ”„ Streaming Implementation](./streaming-implementation.md)** - Como funciona o streaming em tempo real
- **[ğŸš€ Vercel AI Integration](./vercel-ai-integration.md)** - IntegraÃ§Ã£o com Vercel AI SDK âœ… **ÃšNICO SISTEMA**

### **Funcionalidades EspecÃ­ficas**

- **[ğŸ’¬ Session Management](./session-management.md)** - Sistema de gerenciamento de sessÃµes
- **[ğŸ”„ Session & Message Flow](./session-message-flow.md)** - **NOVO**: Arquitetura de fluxo de sessÃµes e mensagens
- **[ğŸ’¾ Message Persistence](./message-persistence.md)** - Armazenamento e recuperaÃ§Ã£o de mensagens
- **[ğŸŒ Translation Keys](./translation-keys.md)** - Chaves de traduÃ§Ã£o e suporte multilÃ­ngue

### **HistÃ³rico da MigraÃ§Ã£o**

- **âœ… Sistema Legacy Completamente Removido** - MigraÃ§Ã£o 100% concluÃ­da
- **[ğŸ“š Arquivo HistÃ³rico](./archive/)** - Documentos da migraÃ§Ã£o arquivados
  - **[ğŸ“‹ Plano de RemoÃ§Ã£o Legacy](./archive/legacy-removal-plan.md)** - DocumentaÃ§Ã£o da remoÃ§Ã£o executada
  - **[ğŸ”„ MigraÃ§Ã£o Vercel AI SDK](./archive/vercel-ai-migration.md)** - HistÃ³rico da implementaÃ§Ã£o
  - **[ğŸ“Š DecisÃµes EstratÃ©gicas](./archive/decisao-estrategica-fallback.md)** - Contexto das decisÃµes

### **Problemas e SoluÃ§Ãµes**

- **[âš ï¸ Known Issues](./known-issues.md)** - Problemas conhecidos e workarounds

## ğŸ”— DependÃªncia do AI Studio

O Chat **depende completamente** do AI Studio para:

- **Provedores de IA**: OpenAI, Anthropic, Google, etc.
- **Modelos DisponÃ­veis**: Apenas modelos ativos no AI Studio aparecem
- **Tokens de API**: Gerenciados centralmente e criptografados
- **ConfiguraÃ§Ãµes**: Limites, parÃ¢metros e prioridades
- **Agentes**: Assistentes personalizados (quando disponÃ­veis)

### Service Layer Integration

```typescript
// Exemplo de integraÃ§Ã£o via Service Layer
const models = await AiStudioService.getAvailableModels({
  teamId: ctx.auth.user.activeTeamId,
  requestingApp: chatAppId,
});
```

## ğŸ”’ SeguranÃ§a

- **Isolamento por SessÃ£o**: Cada conversa Ã© isolada por usuÃ¡rio e team
- **AutenticaÃ§Ã£o**: Integrado com o sistema de auth do Kodix
- **Sem ExposiÃ§Ã£o de Tokens**: Tokens de API nunca chegam ao frontend
- **ValidaÃ§Ã£o de Acesso**: VerificaÃ§Ã£o de permissÃµes em todas as operaÃ§Ãµes

## ğŸ” Debugging e Troubleshooting

### VerificaÃ§Ã£o de Status

```bash
# Verificar se o sistema estÃ¡ usando Vercel AI SDK
curl -X POST http://localhost:3000/api/chat/stream \
  -H "Content-Type: application/json" \
  -d '{"chatSessionId": "SESSION_ID", "content": "test"}' \
  -I | grep "X-Powered-By"

# Resposta esperada:
# X-Powered-By: Vercel-AI-SDK
```

### Logs Importantes

```bash
# Logs do Vercel AI SDK (Ãºnico sistema)
grep "ğŸš€ \[VERCEL_AI\]" logs/app.log

# Logs do auto-save
grep "ğŸ’¾ AUTO-SAVE" logs/app.log

# Logs do adapter
grep "\[CHAT\]" logs/app.log
```

### Problemas Comuns

1. **Modelo NÃ£o Encontrado**

   - Verificar configuraÃ§Ã£o no AI Studio
   - Confirmar que modelo estÃ¡ ativo para o team

2. **Token InvÃ¡lido**

   - Verificar tokens no AI Studio
   - Confirmar criptografia e descriptografia

3. **Erro de Provider**

   - Verificar se provider Ã© suportado (OpenAI, Anthropic)
   - Confirmar configuraÃ§Ã£o no AI Studio

4. **Streaming Interrompido**

   - Verificar conexÃ£o de rede
   - Consultar logs do VercelAIAdapter

5. **Token Usage Badge NÃ£o Aparece**

   - Verificar se as traduÃ§Ãµes estÃ£o disponÃ­veis
   - Confirmar chaves `tokenUsage.*` em `locales/kdx/[pt-BR|en].json`

6. **Auto-focus NÃ£o Funciona**
   - Verificar se input ref estÃ¡ corretamente configurado
   - Confirmar que streaming completou sem mudanÃ§a de sessÃ£o

## ğŸ’¡ ImplementaÃ§Ã£o TÃ©cnica

### Native Vercel AI SDK

100% implementaÃ§Ã£o nativa com lifecycle callbacks:

```typescript
// Native streamText with built-in callbacks
const result = streamText({
  model: vercelModel,
  messages: formattedMessages,
  temperature: 0.7,
  maxTokens: 4000,
  // âœ… Native onFinish callback for auto-save
  onFinish: async ({ text, usage, finishReason }) => {
    await ChatService.createMessage({
      chatSessionId: session.id,
      senderRole: "ai",
      content: text,
      status: "ok",
      metadata: {
        usage,
        finishReason,
        migrationStatus: "native-implementation",
      },
    });
  },
  // âœ… Native onError callback
  onError: (error) => {
    console.error("Stream error:", error);
  },
});

// Native response format
return result.toDataStreamResponse();
```

### BenefÃ­cios da MigraÃ§Ã£o Nativa

- **100% Compatibilidade** - Segue todos os padrÃµes oficiais do Vercel AI SDK
- **Performance MÃ¡xima** - Sem camadas de abstraÃ§Ã£o customizadas
- **Lifecycle Callbacks Nativos** - `onFinish` e `onError` integrados
- **Observabilidade Completa** - Token usage e mÃ©tricas nativas
- **Future-Proof** - CompatÃ­vel com todas as features futuras do SDK
- **Error Handling Robusto** - Tratamento de erros padrÃ£o do SDK
- **Response Format Nativo** - `toDataStreamResponse()` oficial

## ğŸš€ Performance

### OtimizaÃ§Ãµes Implementadas

- **Streaming Direto**: Vercel AI SDK com otimizaÃ§Ãµes nativas
- **Auto-Save AssÃ­ncrono**: Salvamento nÃ£o bloqueia streaming
- **GestÃ£o Inteligente de Tokens**: Truncamento automÃ¡tico de contexto
- **Ãndices Otimizados**: Queries de banco de dados otimizadas
- **CÃ³digo Limpo**: Sem overhead de sistemas legacy

### MÃ©tricas Monitoradas

- Tempo de resposta do primeiro token
- Taxa de sucesso das APIs
- Throughput de streaming
- Uso de tokens por sessÃ£o
- LatÃªncia do auto-save

## ğŸ”§ Desenvolvimento

### Estrutura de Arquivos

```
apps/kdx/src/app/api/chat/
â”œâ”€â”€ stream/route.ts              # âœ… MIGRADO: 100% native Vercel AI SDK
â”œâ”€â”€ monitoring/route.ts          # Monitoramento do sistema
â””â”€â”€ route.ts                     # Endpoint bÃ¡sico

packages/api/src/internal/
â”œâ”€â”€ adapters/
â”‚   â””â”€â”€ vercel-ai-adapter.ts     # âš ï¸ LEGACY: Para remoÃ§Ã£o (nÃ£o mais usado)
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ chat.service.ts          # Service layer do Chat
â”‚   â””â”€â”€ ai-studio.service.ts     # IntegraÃ§Ã£o com AI Studio
â””â”€â”€ types/
    â””â”€â”€ ai/
        â””â”€â”€ vercel-adapter.types.ts  # âš ï¸ LEGACY: Para remoÃ§Ã£o

Chat Components (apps/kdx/src/app/[locale]/(authed)/apps/chat/):
â”œâ”€â”€ _components/
â”‚   â”œâ”€â”€ token-usage-badge.tsx    # âœ… NOVO: Badge com Popover de token usage
â”‚   â”œâ”€â”€ chat-window.tsx          # âœ… UPDATED: Auto-focus implementado
â”‚   â””â”€â”€ chat-window-session.tsx  # âœ… UPDATED: Auto-focus implementado
â”œâ”€â”€ [sessionId]/page.tsx         # âœ… UPDATED: Interface limpa sem tÃ­tulo
â””â”€â”€ page.tsx                     # PÃ¡gina principal

Locales (packages/locales/src/messages/kdx/):
â”œâ”€â”€ pt-BR.json                   # âœ… UPDATED: Novas chaves tokenUsage.*
â””â”€â”€ en.json                      # âœ… UPDATED: Novas chaves tokenUsage.*

DocumentaÃ§Ã£o (docs/subapps/chat/):
â””â”€â”€ vercel-ai-standards-migration-plan.md  # âœ… NOVO: Plano futuro de padronizaÃ§Ã£o
```

### Comandos Ãšteis

```bash
# Executar servidor de desenvolvimento
pnpm dev:kdx

# Testar endpoint de monitoramento
curl http://localhost:3000/api/chat/monitoring?action=status

# Verificar logs em tempo real
tail -f logs/app.log | grep "VERCEL_AI"

# Executar testes do adapter
pnpm test packages/api/src/internal/adapters/
```

## ğŸ”— Links Relacionados

- **[AI Studio](../ai-studio/README.md)** - **PRÃ‰-REQUISITO** para configurar modelos e tokens
- **[SubApp Architecture](../../architecture/subapp-architecture.md)** - PadrÃµes de SubApps
- **[Arquitetura Geral](../../architecture/README.md)** - Arquitetura do monorepo

## ğŸ“š Recursos Relacionados

- **[ğŸ“ SubApp Architecture Guide](../../architecture/subapp-architecture.md)** - PadrÃµes e processo de criaÃ§Ã£o de SubApps
- **[ğŸ”§ Backend Development Guide](../../architecture/backend-guide.md)** - PadrÃµes gerais de desenvolvimento backend
- **[ğŸ¨ Frontend Development Guide](../../architecture/frontend-guide.md)** - PadrÃµes de desenvolvimento frontend

## ğŸ¯ PrÃ³ximos Passos

### Melhorias Planejadas

- [ ] Suporte a mais providers via Vercel AI SDK
- [ ] Tool calling para funÃ§Ãµes avanÃ§adas
- [ ] Structured output para respostas formatadas
- [ ] Streaming de imagens e arquivos
- [ ] Cache inteligente de respostas
- [ ] MÃ©tricas avanÃ§adas de performance

### ExpansÃµes Futuras

- [ ] IntegraÃ§Ã£o com agentes do AI Studio
- [ ] Suporte a conversas em grupo
- [ ] Compartilhamento de conversas
- [ ] Templates de prompts
- [ ] AnÃ¡lise de sentimentos
- [ ] Resumos automÃ¡ticos de conversas

---

**ğŸ‰ O Chat SubApp agora opera com 100% padrÃµes nativos do Vercel AI SDK!**

**ğŸ“Š BenefÃ­cios da MigraÃ§Ã£o Completa:**

- âœ… **100% Compatibilidade Nativa** - ImplementaÃ§Ã£o oficial do Vercel AI SDK
- âœ… **Lifecycle Callbacks Integrados** - `onFinish` e `onError` nativos
- âœ… **Response Format PadrÃ£o** - `toDataStreamResponse()` oficial
- âœ… **Performance MÃ¡xima** - Sem overhead de adaptadores customizados
- âœ… **Future-Proof** - CompatÃ­vel com todas as features futuras
- âœ… **Observabilidade Completa** - Token usage e mÃ©tricas nativas
- âœ… **Error Handling Robusto** - Tratamento de erros padrÃ£o do SDK
