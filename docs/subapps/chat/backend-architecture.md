# Backend Architecture - Chat SubApp

## ‚öôÔ∏è Vis√£o Geral

O backend do Chat √© constru√≠do com tRPC para APIs type-safe e um endpoint HTTP dedicado para streaming. A arquitetura prioriza performance e integra√ß√£o segura com o AI Studio.

## üèóÔ∏è Estrutura de APIs

### Routers tRPC

#### Router Principal (`chat/_router.ts`)

```typescript
export const chatRouter = {
  // Sess√µes
  buscarSessoes: protectedProcedure.query(),
  criarSessao: protectedProcedure.mutation(),
  atualizarSessao: protectedProcedure.mutation(),
  deletarSessao: protectedProcedure.mutation(),

  // Mensagens
  buscarMensagens: protectedProcedure.query(),
  enviarMensagem: protectedProcedure.mutation(),

  // Auto-cria√ß√£o
  autoCreateSessionWithMessage: protectedProcedure.mutation(),
} satisfies TRPCRouterRecord;
```

### Endpoint de Streaming

- **Rota**: `/api/chat/stream`
- **M√©todo**: POST
- **Autentica√ß√£o**: Via cookies de sess√£o
- **Protocolo**: Server-Sent Events (SSE)

## üóÑÔ∏è Modelo de Dados

### Tabela `chatSession`

```sql
CREATE TABLE chatSession (
  id VARCHAR(21) PRIMARY KEY,
  title VARCHAR(255),
  teamId VARCHAR(21) NOT NULL,
  userId VARCHAR(21) NOT NULL,
  aiModelId VARCHAR(21),
  aiAgentId VARCHAR(21),
  createdAt TIMESTAMP DEFAULT NOW(),
  updatedAt TIMESTAMP DEFAULT NOW() ON UPDATE NOW(),
  FOREIGN KEY (teamId) REFERENCES team(id),
  FOREIGN KEY (userId) REFERENCES user(id),
  FOREIGN KEY (aiModelId) REFERENCES aiModel(id),
  FOREIGN KEY (aiAgentId) REFERENCES aiAgent(id)
);
```

### Tabela `chatMessage`

```sql
CREATE TABLE chatMessage (
  id VARCHAR(21) PRIMARY KEY,
  chatSessionId VARCHAR(21) NOT NULL,
  senderRole ENUM('user', 'ai', 'system') NOT NULL,
  content TEXT NOT NULL,
  status VARCHAR(50) DEFAULT 'ok',
  metadata JSON,
  createdAt TIMESTAMP DEFAULT NOW(),
  updatedAt TIMESTAMP DEFAULT NOW() ON UPDATE NOW(),
  FOREIGN KEY (chatSessionId) REFERENCES chatSession(id) ON DELETE CASCADE
);
```

## üîÑ Fluxo de Processamento

### 1. Cria√ß√£o de Sess√£o

```typescript
// Handler simplificado
export const criarSessaoHandler = async ({ ctx, input }) => {
  const session = await chatRepository.ChatSessionRepository.create({
    title: input.title || "Nova Conversa",
    teamId: ctx.auth.user.activeTeamId,
    userId: ctx.auth.user.id,
    aiModelId: input.modelId,
  });

  return session;
};
```

### 2. Envio de Mensagem

O fluxo de envio envolve m√∫ltiplas etapas:

1. **Valida√ß√£o**: Verifica sess√£o e permiss√µes
2. **Persist√™ncia**: Salva mensagem do usu√°rio
3. **Streaming**: Inicia resposta da IA
4. **Finaliza√ß√£o**: Salva resposta completa

### 3. Streaming de Resposta

```typescript
// Endpoint de streaming simplificado
export async function POST(request: NextRequest) {
  // 1. Validar sess√£o e autentica√ß√£o
  const { chatSessionId, content } = await request.json();
  const session = await ChatService.findSessionById(chatSessionId);

  // 2. Buscar modelo e configura√ß√µes
  const model = await AiStudioService.getModelById({
    modelId: session.aiModelId,
    teamId: session.teamId,
    requestingApp: chatAppId,
  });

  // 3. Buscar token do provider
  const token = await AiStudioService.getProviderToken({
    providerId: model.providerId,
    teamId: session.teamId,
    requestingApp: chatAppId,
  });

  // 4. Configurar streaming
  const stream = await createStreamingResponse({
    model,
    messages: formattedMessages,
    token: token.token,
  });

  return new Response(stream);
}
```

## üîê Seguran√ßa e Isolamento

### Isolamento por Team

Todas as queries incluem valida√ß√£o de `teamId`:

```typescript
// Repository sempre filtra por team
export const findByTeam = async (teamId: string) => {
  return db.query.chatSession.findMany({
    where: eq(chatSession.teamId, teamId),
  });
};
```

### Valida√ß√£o de Permiss√µes

```typescript
// Middleware verifica acesso
const validateSessionAccess = async (sessionId, userId, teamId) => {
  const session = await findSessionById(sessionId);

  if (!session || session.teamId !== teamId) {
    throw new TRPCError({
      code: "NOT_FOUND",
      message: "Sess√£o n√£o encontrada",
    });
  }

  return session;
};
```

## üîó Integra√ß√£o com AI Studio

### Service Layer

O Chat usa `AiStudioService` para toda comunica√ß√£o:

```typescript
// Buscar modelos dispon√≠veis
const models = await AiStudioService.getAvailableModels({
  teamId: ctx.auth.user.activeTeamId,
  requestingApp: chatAppId,
});

// Buscar token do provider
const token = await AiStudioService.getProviderToken({
  providerId: model.providerId,
  teamId: ctx.auth.user.activeTeamId,
  requestingApp: chatAppId,
});
```

### Fallback de Modelo

Se a sess√£o n√£o tem modelo configurado:

1. Busca modelos dispon√≠veis do time
2. Seleciona o primeiro como padr√£o
3. Atualiza a sess√£o automaticamente

## üìä Gest√£o de Tokens

### C√°lculo Inteligente

```typescript
// Estimar tokens de uma mensagem
const estimateTokens = (text: string): number => {
  return Math.ceil(text.length / 3.5) + 10;
};

// Gerenciar limite de contexto
const manageContext = (messages, maxTokens) => {
  const maxInput = Math.floor(maxTokens * 0.7); // 70% para input

  // Preservar mensagens do sistema
  const systemMessages = messages.filter((m) => m.role === "system");

  // Truncar hist√≥rico se necess√°rio
  const conversationMessages = truncateToFit(
    messages.filter((m) => m.role !== "system"),
    maxInput - estimateTokens(systemMessages),
  );

  return [...systemMessages, ...conversationMessages];
};
```

### Limites por Modelo

O sistema obt√©m limites espec√≠ficos do AI Studio:

- Limites configurados por modelo no AI Studio
- Fallback para limites padr√£o se n√£o especificado
- Consulte [Model Configuration](../ai-studio/model-configuration.md) para detalhes

## üåç Internacionaliza√ß√£o

### System Prompts Multil√≠ngues

```typescript
// Detectar idioma do usu√°rio
const userLocale = detectUserLocale(request);

// Aplicar prompt no idioma correto
const systemPrompt =
  userLocale === "pt-BR"
    ? "Voc√™ √© um assistente √∫til e responde sempre em portugu√™s brasileiro."
    : "You are a helpful assistant and always respond in English.";
```

### Detec√ß√£o de Idioma

1. Cookie `NEXT_LOCALE`
2. Pathname da URL
3. Header `Accept-Language`
4. Fallback para `pt-BR`

## üöÄ Performance

### Otimiza√ß√µes Implementadas

- **Streaming Real-time**: Resposta aparece progressivamente
- **Pagina√ß√£o**: Mensagens carregadas sob demanda
- **Cache**: Modelos dispon√≠veis s√£o cacheados
- **√çndices**: Queries otimizadas com √≠ndices apropriados

### M√©tricas Monitoradas

- Tempo de resposta do primeiro token
- Taxa de sucesso/erro das APIs
- Uso de tokens por sess√£o
- Lat√™ncia do streaming

## üîß Tratamento de Erros

### Erros Espec√≠ficos de Provider

```typescript
// Token inv√°lido
if (response.status === 401) {
  throw new Error("Token inv√°lido. Verifique configura√ß√£o no AI Studio");
}

// Limite excedido
if (response.status === 429) {
  throw new Error("Limite de uso excedido. Verifique sua conta do provider");
}

// Modelo n√£o encontrado
if (response.status === 404) {
  throw new Error(`Modelo n√£o encontrado. Configure no AI Studio`);
}
```

### Recovery Strategies

1. **Modelo n√£o dispon√≠vel**: Fallback para modelo padr√£o via AI Studio
2. **Token expirado**: Redirecionar para configura√ß√£o no AI Studio
3. **Limite excedido**: Sugerir truncar contexto ou trocar modelo

## üìù Logs e Auditoria

### Logs de Debugging

```typescript
console.log("üîµ [API] POST streaming recebido");
console.log("üü¢ [API] Dados recebidos:", { chatSessionId, content });
console.log("üéØ [DEBUG] Usando modelo:", model.name);
console.log("‚úÖ [API] Mensagem salva com metadata");
```

### Metadata de Mensagens

Cada mensagem salva metadata relevante:

```json
{
  "requestedModel": "gpt-4",
  "actualModelUsed": "gpt-4",
  "providerId": "provider_123",
  "providerName": "OpenAI",
  "usage": {
    "promptTokens": 150,
    "completionTokens": 200,
    "totalTokens": 350
  },
  "timestamp": "2024-01-01T00:00:00Z"
}
```

## üîÑ Pr√≥ximas Melhorias

### Planejadas

- [ ] Suporte a m√∫ltiplos agentes
- [ ] Cache de respostas comuns
- [ ] Compress√£o de hist√≥rico
- [ ] M√©tricas detalhadas de uso
- [ ] Webhooks para integra√ß√µes
