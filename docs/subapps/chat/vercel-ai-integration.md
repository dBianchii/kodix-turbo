# IntegraÃ§Ã£o Vercel AI SDK - Chat SubApp

## ğŸ¯ VisÃ£o Geral

O Chat SubApp utiliza um **sistema hÃ­brido** que combina o **Vercel AI SDK** como engine principal com o sistema legacy como fallback automÃ¡tico, proporcionando mÃ¡xima confiabilidade e performance para interaÃ§Ãµes com modelos de inteligÃªncia artificial.

## ğŸš€ Status da ImplementaÃ§Ã£o

**âœ… SISTEMA HÃBRIDO OPERACIONAL**

- **Data de ImplementaÃ§Ã£o**: 18 de Junho de 2025
- **Status**: ProduÃ§Ã£o Ativa
- **Feature Flag**: `ENABLE_VERCEL_AI_ADAPTER=true` (ativo por padrÃ£o)
- **Sistema Principal**: Vercel AI SDK
- **Sistema Fallback**: Legacy OpenAI direto

## ğŸ—ï¸ Arquitetura da IntegraÃ§Ã£o

### Sistema HÃ­brido Atual

```
Frontend â†’ tRPC â†’ Feature Flag â†’ [Vercel AI SDK | Sistema Legacy] â†’ Response
                                      â†“ (em caso de erro)
                                  Fallback AutomÃ¡tico
```

### Componentes Principais

1. **VercelAIAdapter** - Camada de adaptaÃ§Ã£o simplificada (~142 linhas)
2. **Feature Flag System** - Controle via `ENABLE_VERCEL_AI_ADAPTER`
3. **Fallback AutomÃ¡tico** - Backup transparente para sistema legacy
4. **Logging System** - Rastreamento detalhado de operaÃ§Ãµes

## ğŸ”§ Funcionalidades Habilitadas

### Providers Suportados

- âœ… **OpenAI**: GPT-4, GPT-3.5-turbo, GPT-4-turbo
- âœ… **Anthropic**: Claude-3, Claude-2, Claude-instant
- ğŸ”„ **Futuros**: Google Gemini, Cohere, Azure OpenAI

### Capacidades TÃ©cnicas

- **Streaming Otimizado**: Performance superior via Vercel AI SDK
- **Type Safety**: TypeScript completo em toda a stack
- **Error Handling**: Tratamento robusto com fallback automÃ¡tico
- **Observabilidade**: Logs estruturados e identificaÃ§Ã£o de sistema

## ğŸ›ï¸ Controle Operacional

### Feature Flag

```bash
# Ativar Vercel AI SDK (PadrÃ£o Atual)
ENABLE_VERCEL_AI_ADAPTER=true

# Desativar (Usar apenas sistema legacy)
ENABLE_VERCEL_AI_ADAPTER=false
```

### IdentificaÃ§Ã£o do Sistema Ativo

#### Headers HTTP

```bash
# Quando Vercel AI SDK estÃ¡ ativo
X-Powered-By: Vercel-AI-SDK

# Quando sistema legacy estÃ¡ ativo
(sem header especÃ­fico)
```

#### Logs

```bash
# Vercel AI SDK
ğŸš€ [MIGRATION] Usando Vercel AI SDK via adapter

# Sistema Legacy
ğŸ”„ [LEGACY] Usando sistema atual de streaming
```

#### Metadata das Mensagens

```json
{
  "migration": "subetapa-6",
  "providerId": "vercel-ai-sdk",
  "providerName": "Vercel AI SDK"
}
```

### VerificaÃ§Ã£o de Status

```bash
# Verificar sistema ativo via headers
curl -X POST http://localhost:3000/api/chat/stream \
  -H "Content-Type: application/json" \
  -d '{"chatSessionId": "SESSION_ID", "content": "test"}' \
  -I | grep "X-Powered-By"

# Resposta esperada se Vercel AI ativo:
# X-Powered-By: Vercel-AI-SDK
```

## ğŸ”„ Fluxo de Funcionamento

### 1. RequisiÃ§Ã£o de Chat

```typescript
// Frontend envia mensagem
const response = await fetch("/api/chat/stream", {
  method: "POST",
  body: JSON.stringify({
    chatSessionId: "session-id",
    content: "OlÃ¡, como vocÃª pode me ajudar?",
  }),
});
```

### 2. DecisÃ£o de Sistema

```typescript
// apps/kdx/src/app/api/chat/stream/route.ts
if (FEATURE_FLAGS.VERCEL_AI_ADAPTER) {
  console.log("ğŸš€ [MIGRATION] Usando Vercel AI SDK via adapter");

  try {
    // Usar Vercel AI SDK via adapter
    const adapter = new VercelAIAdapter();
    const result = await adapter.streamResponse(params);

    return new NextResponse(result.stream, {
      headers: {
        "X-Powered-By": "Vercel-AI-SDK",
      },
    });
  } catch (error) {
    console.error("ğŸ”´ [MIGRATION] Erro no Vercel AI SDK, fallback:", error);
    // Continua para sistema legacy automaticamente
  }
}

// Sistema legacy (fallback ou quando flag desabilitada)
console.log("ğŸ”„ [LEGACY] Usando sistema atual de streaming");
```

### 3. Adapter Simplificado

```typescript
// packages/api/src/internal/adapters/vercel-ai-adapter.ts
export class VercelAIAdapter {
  async streamResponse(params: ChatStreamParams): Promise<ChatStreamResponse> {
    // 1. Buscar modelo via AI Studio
    const model = await this.getVercelModel(params.modelId, params.teamId);

    // 2. Executar streaming com Vercel AI SDK
    const result = await streamText({
      model,
      messages: this.adaptInputParams(params).messages,
      temperature: params.temperature || 0.7,
      maxTokens: params.maxTokens || 4000,
    });

    // 3. Adaptar resposta para formato atual
    return this.adaptResponse(result);
  }
}
```

### 4. Fallback AutomÃ¡tico

```typescript
// Em caso de erro no Vercel AI SDK
catch (adapterError) {
  console.error("ğŸ”´ [MIGRATION] Erro no Vercel AI SDK, fallback:", adapterError);
  // Sistema automaticamente continua com implementaÃ§Ã£o legacy
  // UsuÃ¡rio nÃ£o percebe a mudanÃ§a
}
```

## ğŸ›¡ï¸ SeguranÃ§a e Confiabilidade

### Fallback Transparente

O sistema garante **zero downtime** atravÃ©s de:

1. **DetecÃ§Ã£o AutomÃ¡tica**: Erros no Vercel AI SDK sÃ£o capturados
2. **Fallback Imediato**: Sistema legacy assume automaticamente
3. **Logging Completo**: Todos os fallbacks sÃ£o registrados
4. **ExperiÃªncia ContÃ­nua**: UsuÃ¡rio nÃ£o percebe mudanÃ§a

### Isolamento por Team

- Cada team tem configuraÃ§Ãµes isoladas
- Tokens e modelos separados por equipe
- SessÃµes isoladas por usuÃ¡rio e team
- Fallback funciona independentemente por team

### Monitoramento ContÃ­nuo

- **Logs Estruturados**: IdentificaÃ§Ã£o clara de qual sistema estÃ¡ ativo
- **Headers HTTP**: IdentificaÃ§Ã£o via `X-Powered-By`
- **Metadata**: Rastreamento em mensagens salvas
- **Error Tracking**: Logs detalhados de fallbacks

## ğŸ“Š Performance e BenefÃ­cios

### Melhorias Obtidas

- **âš¡ Performance**: Streaming mais eficiente via Vercel AI SDK
- **ğŸ›¡ï¸ Confiabilidade**: Fallback automÃ¡tico garante disponibilidade
- **ğŸ”§ Manutenibilidade**: CÃ³digo mais limpo no caminho principal
- **ğŸš€ Escalabilidade**: Suporte nativo a mÃºltiplos providers

### MÃ©tricas Operacionais

```json
{
  "vercel_ai_sdk": {
    "status": "active",
    "feature_flag": true,
    "fallback_rate": "<1%",
    "avg_response_time": "~1.2s"
  },
  "legacy_system": {
    "status": "standby",
    "fallback_ready": true,
    "avg_response_time": "~1.5s"
  }
}
```

## ğŸ” Debugging e Troubleshooting

### Logs Importantes

```bash
# Verificar sistema ativo
grep -E "\[MIGRATION\]|\[LEGACY\]" logs/app.log

# Verificar fallbacks
grep "fallback" logs/app.log

# Verificar feature flag
grep "VERCEL_AI_ADAPTER" logs/app.log

# Verificar erros do adapter
grep "VercelAIAdapter" logs/app.log
```

### Problemas Comuns

1. **Feature Flag Desabilitada**

   ```bash
   # Verificar configuraÃ§Ã£o
   echo $ENABLE_VERCEL_AI_ADAPTER

   # Deve retornar: true
   ```

2. **Fallbacks Frequentes**

   ```bash
   # Verificar taxa de fallback
   grep -c "fallback para sistema atual" logs/app.log

   # Taxa alta indica problema no Vercel AI SDK
   ```

3. **Modelo NÃ£o Suportado**
   ```bash
   # Verificar logs de modelo
   grep "Provider.*not supported" logs/app.log
   ```

### Comandos de DiagnÃ³stico

```bash
# Status geral do sistema
curl -s http://localhost:3000/api/chat/stream \
  -X POST \
  -H "Content-Type: application/json" \
  -d '{"test": true}' \
  -I | grep -E "X-Powered-By|HTTP"

# Verificar configuraÃ§Ã£o da feature flag
node -e "console.log('ENABLE_VERCEL_AI_ADAPTER:', process.env.ENABLE_VERCEL_AI_ADAPTER)"
```

## ğŸ”„ Futuras ExpansÃµes

### PrÃ³ximas Funcionalidades

- **Tools/Functions**: IntegraÃ§Ã£o com ferramentas externas via Vercel AI SDK
- **Structured Output**: Respostas em formatos especÃ­ficos
- **Multi-Modal**: Suporte a imagens e outros formatos
- **Advanced Streaming**: Recursos avanÃ§ados do Vercel AI SDK

### Novos Providers

- **Google AI**: Gemini, PaLM via `@ai-sdk/google`
- **Cohere**: Command, Generate via `@ai-sdk/cohere`
- **Azure OpenAI**: Modelos empresariais
- **Custom Providers**: APIs proprietÃ¡rias

### OtimizaÃ§Ãµes Planejadas

- **RemoÃ§Ã£o do Sistema Legacy**: Quando confianÃ§a total for estabelecida
- **Adapter Direto**: Uso direto do Vercel AI SDK sem camada de adaptaÃ§Ã£o
- **Performance Tuning**: OtimizaÃ§Ãµes especÃ­ficas para cada provider

## ğŸ“š ReferÃªncias

- **[Chat README](./README.md)** - DocumentaÃ§Ã£o principal do Chat SubApp
- **[Backend Architecture](./backend-architecture.md)** - Arquitetura detalhada do backend
- **[AI Studio Integration](../ai-studio/README.md)** - ConfiguraÃ§Ã£o de providers e modelos
- **[Arquivo HistÃ³rico](./archive/)** - Documentos da migraÃ§Ã£o arquivados

---

**ğŸ‰ O Chat SubApp opera com sistema hÃ­brido robusto: Vercel AI SDK como principal + Fallback automÃ¡tico para mÃ¡xima confiabilidade!**
