# Model Configuration - AI Studio

## üß† Vis√£o Geral

O sistema de modelos permite configurar e gerenciar diferentes modelos de IA dispon√≠veis nos provedores. Cada modelo tem caracter√≠sticas espec√≠ficas como limites de tokens, custos e capacidades.

## üìä Gest√£o de Modelos

### Ativar/Desativar Modelos

1. Acesse a aba **Modelos**
2. Localize o modelo desejado
3. Use o toggle para ativar/desativar
4. Mudan√ßas refletem imediatamente

### Configurar Par√¢metros

#### Limites de Tokens

- **Input**: M√°ximo de tokens de entrada
- **Output**: M√°ximo de tokens de resposta
- **Total**: Limite combinado (contexto)

#### Configura√ß√µes Avan√ßadas

```json
{
  "temperature": 0.7,
  "top_p": 1.0,
  "frequency_penalty": 0,
  "presence_penalty": 0
}
```

### Sistema de Prioridade

- **Alta Prioridade (90-100)**: Modelos preferenciais
- **M√©dia Prioridade (50-89)**: Uso regular
- **Baixa Prioridade (1-49)**: Fallback

## üéØ Modelos Populares

### GPT-4 (OpenAI)

- **Tokens**: 128k contexto
- **Uso**: Tarefas complexas, racioc√≠nio
- **Custo**: Alto

### Claude 3 Opus (Anthropic)

- **Tokens**: 200k contexto
- **Uso**: An√°lise de documentos longos
- **Custo**: Alto

### Gemini Pro (Google)

- **Tokens**: 32k contexto
- **Uso**: Multimodal, velocidade
- **Custo**: M√©dio

### GPT-3.5 Turbo (OpenAI)

- **Tokens**: 16k contexto
- **Uso**: Tarefas gerais, chat
- **Custo**: Baixo

## ‚öôÔ∏è Configura√ß√µes por Equipe

### Modelo Padr√£o

1. Defina prioridades nos modelos
2. Sistema seleciona o de maior prioridade ativo
3. Fallback autom√°tico se indispon√≠vel

### Filtros e Organiza√ß√£o

- Filtrar por provedor
- Buscar por nome
- Ordenar por prioridade

## üîß Casos de Uso

### Para Chat Geral

```json
{
  "model": "gpt-3.5-turbo",
  "temperature": 0.7,
  "max_tokens": 2000
}
```

### Para C√≥digo

```json
{
  "model": "claude-3-sonnet",
  "temperature": 0.3,
  "max_tokens": 4000
}
```

### Para An√°lise

```json
{
  "model": "gpt-4-turbo",
  "temperature": 0.5,
  "max_tokens": 8000
}
```

## üí∞ Considera√ß√µes de Custo

### Otimiza√ß√£o

- Use modelos menores para tarefas simples
- Configure limites de tokens apropriados
- Monitore uso por modelo

### Estimativas

- **GPT-3.5**: ~$0.002/1k tokens
- **GPT-4**: ~$0.03/1k tokens
- **Claude**: Varia por tier

## üö® Problemas Comuns

### Modelo n√£o aparece no Chat

- Confirme que est√° ativo
- Verifique se provedor tem token
- Aguarde cache atualizar (5 min)

### Erro de limite de tokens

- Reduza max_tokens
- Use modelo com maior contexto
- Divida requisi√ß√µes grandes

### Performance lenta

- Considere modelo mais r√°pido
- Ajuste temperatura (menor = mais r√°pido)
- Use streaming quando poss√≠vel

## üí° Boas Pr√°ticas

### Sele√ß√£o de Modelo

- Combine capacidade com custo
- Teste diferentes modelos
- Documente casos de uso

### Configura√ß√£o

- Comece com defaults
- Ajuste baseado em resultados
- Mantenha consist√™ncia

### Manuten√ß√£o

- Revise modelos n√£o utilizados
- Atualize limites conforme necess√°rio
- Monitore novos lan√ßamentos
