# Configuration Guide - AI Studio SubApp

## üìã Vis√£o Geral

Este guia cobre a configura√ß√£o inicial do AI Studio, incluindo setup de provedores, modelos e tokens. O sistema vem com dados pr√©-configurados (seed) dos principais provedores de IA.

## üè¢ Provedores Inclu√≠dos

### Principais Provedores Comerciais

- **OpenAI** - GPT-4, GPT-3.5, etc.
- **Anthropic** - Claude 3.5 Sonnet, Haiku
- **Google** - Gemini 1.5 Pro, Flash

### Provedores Emergentes

- **Mistral AI** - Mistral Large, 7B
- **Cohere** - Command R+
- **Perplexity** - Sonar Pro
- **xAI** - Grok Beta

### Provedores Open Source

- **Hugging Face** - Modelos inference
- **Together AI** - Modelos hospedados
- **Groq** - Execu√ß√£o ultrarr√°pida

### Provedores Locais

- **Ollama** - Execu√ß√£o local
- **LM Studio** - Interface local

## ü§ñ Modelos Pr√©-Configurados

### OpenAI

- **GPT-4o** - Modelo mais recente
- **GPT-4o Mini** - Vers√£o econ√¥mica
- **GPT-4 Turbo** - Dados at√© abril 2024
- **GPT-3.5 Turbo** - R√°pido e econ√¥mico

### Anthropic

- **Claude 3.5 Sonnet** - Melhor racioc√≠nio
- **Claude 3.5 Haiku** - Mais r√°pido
- **Claude 3 Opus** - Tarefas complexas (desabilitado)

### Google

- **Gemini 1.5 Pro** - Contexto de 2M tokens
- **Gemini 1.5 Flash** - Mais r√°pido
- **Gemini Pro** - Vers√£o cl√°ssica

### Outros

- **Mistral Large** - Modelo flagship
- **Command R+** - Para RAG
- **Sonar Pro** - Com busca web
- **Llama 3 70B** - Via Groq

## üöÄ Primeiros Passos

### 1. Acessar AI Studio

```bash
# Executar o projeto
pnpm dev:kdx

# Acessar: http://localhost:3000/apps/aiStudio
```

### 2. Configurar Tokens de API

1. V√° para a se√ß√£o **Tokens**
2. Adicione suas chaves de API reais:
   - OpenAI: `sk-...`
   - Anthropic: `sk-ant-...`
   - Google: API key do Google AI
3. Os tokens s√£o criptografados automaticamente

### 3. Ativar Modelos

1. V√° para a se√ß√£o **Modelos**
2. Ative os modelos que deseja usar
3. Configure limites de tokens se necess√°rio

### 4. Criar Agentes

1. V√° para a se√ß√£o **Agentes**
2. Crie assistentes personalizados
3. Configure prompts de sistema
4. Associe a modelos espec√≠ficos

## ‚öôÔ∏è Configura√ß√£o Padr√£o

### Modelos Habilitados

- Modelos principais comerciais
- Modelos de custo baixo/m√©dio
- Modelos open source gratuitos

### Modelos Desabilitados

- **Claude 3 Opus** - Mais caro
- **Grok Beta** - Ainda em beta
- **Modelos locais** - Requerem setup local

### Configura√ß√µes T√©cnicas

Cada modelo inclui:

- **maxTokens**: Limite padr√£o
- **temperature**: 0.7 padr√£o
- **pricing**: Custo por token
- **description**: Descri√ß√£o detalhada

## üîí Seguran√ßa

### Tokens Criptografados

- Criptografia **AES-256-GCM**
- Armazenamento seguro no banco
- Nunca expostos em logs ou respostas

### Isolamento por Equipe

- Cada equipe tem seus pr√≥prios tokens
- Recursos isolados por `teamId`
- Valida√ß√£o autom√°tica de acesso

## üîß Personaliza√ß√£o

### Adicionar Novo Provedor

1. V√° para **Provedores**
2. Clique em "Criar Provedor"
3. Configure nome, tipo e URL base
4. Adicione token na se√ß√£o **Tokens**

### Adicionar Novo Modelo

1. V√° para **Modelos**
2. Clique em "Criar Modelo"
3. Associe a um provedor existente
4. Configure par√¢metros espec√≠ficos

### Configurar Modelo Local

```bash
# Para Ollama
ollama run llama3:8b

# Configurar no AI Studio:
# Provider: Ollama
# Base URL: http://localhost:11434/api
# Modelo: llama3:8b
```

## üìä Informa√ß√µes dos Modelos

### Estrutura de Configura√ß√£o

```typescript
{
  name: "GPT-4o",
  providerId: "openai-provider-id",
  maxTokens: 4096,
  enabled: true,
  config: {
    temperature: 0.7,
    pricing: {
      input: 0.005,   // USD por 1K tokens
      output: 0.015   // USD por 1K tokens
    },
    description: "Modelo mais recente da OpenAI",
    version: "gpt-4o"
  }
}
```

## üõ†Ô∏è Manuten√ß√£o

### Atualizar Configura√ß√µes

1. **Via Interface**: Edite diretamente no AI Studio
2. **Via Banco**: Execute seeds atualizados
3. **Via API**: Use endpoints de atualiza√ß√£o

### Monitoramento

- **Uso por modelo**: M√©tricas integradas
- **Custos**: Tracking autom√°tico
- **Performance**: Tempo de resposta
- **Erros**: Logs centralizados

## üí° Dicas de Uso

### Para Desenvolvimento

- Use **GPT-3.5 Turbo** para testes (mais barato)
- Configure **temperature baixa** (0.1-0.3) para c√≥digo
- Use **Gemini Flash** para respostas r√°pidas

### Para Produ√ß√£o

- **GPT-4o** para qualidade m√°xima
- **Claude 3.5 Sonnet** para racioc√≠nio complexo
- **Gemini Pro** para contexto longo

### Para Economia

- **GPT-4o Mini** para uso geral
- **Claude Haiku** para tarefas simples
- **Modelos locais** para m√°xima economia

## üîó Pr√≥ximos Passos

1. **Configure tokens** reais dos provedores
2. **Teste modelos** atrav√©s do chat
3. **Crie agentes** personalizados
4. **Monitor custos** atrav√©s das m√©tricas
5. **Explore bibliotecas** de conhecimento

A configura√ß√£o inicial fornece uma base s√≥lida para come√ßar a usar IA imediatamente, com possibilidade de expans√£o conforme necess√°rio.
