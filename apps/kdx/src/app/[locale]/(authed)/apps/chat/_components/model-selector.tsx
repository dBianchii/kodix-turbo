"use client";

import { memo, useCallback, useMemo } from "react";
import { useQuery, useQueryClient } from "@tanstack/react-query";
import { Check, ChevronDown } from "lucide-react";

import { cn } from "@kdx/ui";
import { Button } from "@kdx/ui/button";
import {
  Command,
  CommandEmpty,
  CommandGroup,
  CommandInput,
  CommandItem,
  CommandList,
} from "@kdx/ui/command";
import { Popover, PopoverContent, PopoverTrigger } from "@kdx/ui/popover";

import { useTRPC } from "~/trpc/react";
import { useChatUserConfig } from "../_hooks/useChatUserConfig";

interface ModelSelectorProps {
  value?: string;
  onValueChange?: (value: string) => void;
  disabled?: boolean;
  placeholder?: string;
  className?: string;
}

// âœ… OTIMIZAÃ‡ÃƒO: Memoizar componente para evitar re-renders desnecessÃ¡rios
export const ModelSelector = memo(function ModelSelector({
  value,
  onValueChange,
  disabled = false,
  placeholder = "Selecione um modelo...",
  className,
}: ModelSelectorProps) {
  const trpc = useTRPC();
  const queryClient = useQueryClient();
  const { savePreferredModel, getPreferredModelId } = useChatUserConfig();

  // âœ… Buscar modelos disponÃ­veis
  const { data: availableModels, isLoading: isLoadingModels } = useQuery(
    trpc.app.aiStudio.findAvailableModels.queryOptions(undefined, {
      staleTime: 5 * 60 * 1000, // âœ… OTIMIZAÃ‡ÃƒO: 5 minutos para reduzir requests
      gcTime: 10 * 60 * 1000,
      refetchOnWindowFocus: false,
    }),
  );

  // âœ… OTIMIZAÃ‡ÃƒO: Memoizar processamento de modelos para evitar re-cÃ¡lculos
  const processedModels = useMemo(() => {
    const allModels = availableModels || [];

    if (process.env.NODE_ENV === "development") {
      console.log(
        "ðŸ” [CHAT_MODEL_SELECTOR] Modelos carregados do backend:",
        allModels.length,
      );
      console.log(
        "ðŸ” [CHAT_MODEL_SELECTOR] Modelos habilitados pelo team:",
        allModels.filter((model: any) => model.teamConfig?.enabled).length,
      );
    }

    // Filtrar apenas modelos habilitados pela equipe
    const enabledModels = allModels.filter(
      (model: any) => model.teamConfig?.enabled === true,
    );

    // Ordenar por nome para melhor UX
    const sortedModels = enabledModels.sort((a: any, b: any) =>
      a.name.localeCompare(b.name),
    );

    return sortedModels;
  }, [availableModels]);

  // âœ… OTIMIZAÃ‡ÃƒO: Memoizar modelo selecionado atual
  const currentModel = useMemo(() => {
    const modelId = value || getPreferredModelId();
    return processedModels.find((model: any) => model.id === modelId);
  }, [value, getPreferredModelId, processedModels]);

  // âœ… OTIMIZAÃ‡ÃƒO: Memoizar funÃ§Ã£o de seleÃ§Ã£o para evitar re-criaÃ§Ã£o
  const handleSelect = useCallback(
    async (modelId: string) => {
      if (process.env.NODE_ENV === "development") {
        console.log("ðŸ”„ [CHAT_MODEL_SELECTOR] Modelo selecionado:", modelId);
      }

      // Atualizar valor local se callback fornecido
      onValueChange?.(modelId);

      // Salvar como preferÃªncia do usuÃ¡rio
      try {
        await savePreferredModel(modelId);

        // Invalidar queries relacionadas para atualizar UI
        queryClient.invalidateQueries(
          trpc.app.aiStudio.findAvailableModels.pathFilter(),
        );

        if (process.env.NODE_ENV === "development") {
          console.log("âœ… [CHAT_MODEL_SELECTOR] PreferÃªncia salva com sucesso");
        }
      } catch (error) {
        console.error(
          "âŒ [CHAT_MODEL_SELECTOR] Erro ao salvar preferÃªncia:",
          error,
        );
      }
    },
    [
      onValueChange,
      savePreferredModel,
      queryClient,
      trpc.app.aiStudio.findAvailableModels,
    ],
  );

  // âœ… OTIMIZAÃ‡ÃƒO: Memoizar texto do botÃ£o para evitar re-cÃ¡lculos
  const buttonText = useMemo(() => {
    if (currentModel) {
      return currentModel.name;
    }
    return placeholder;
  }, [currentModel, placeholder]);

  // âœ… OTIMIZAÃ‡ÃƒO: Memoizar classe do botÃ£o
  const buttonClassName = useMemo(() => {
    return cn(
      "w-full justify-between",
      !currentModel && "text-muted-foreground",
      className,
    );
  }, [currentModel, className]);

  if (isLoadingModels) {
    return (
      <Button
        variant="outline"
        disabled
        className={cn("w-full justify-between", className)}
      >
        Carregando modelos...
        <ChevronDown className="ml-2 h-4 w-4 shrink-0 opacity-50" />
      </Button>
    );
  }

  return (
    <Popover>
      <PopoverTrigger asChild>
        <Button
          variant="outline"
          role="combobox"
          disabled={disabled}
          className={buttonClassName}
        >
          {buttonText}
          <ChevronDown className="ml-2 h-4 w-4 shrink-0 opacity-50" />
        </Button>
      </PopoverTrigger>
      <PopoverContent className="w-full p-0" align="start">
        <Command>
          <CommandInput placeholder="Buscar modelo..." />
          <CommandEmpty>Nenhum modelo encontrado.</CommandEmpty>
          <CommandList>
            <CommandGroup>
              {processedModels.map((model: any) => (
                <CommandItem
                  key={model.id}
                  value={model.name}
                  onSelect={() => handleSelect(model.id)}
                >
                  <Check
                    className={cn(
                      "mr-2 h-4 w-4",
                      currentModel?.id === model.id
                        ? "opacity-100"
                        : "opacity-0",
                    )}
                  />
                  <div className="flex flex-col">
                    <span className="font-medium">{model.name}</span>
                    {model.description && (
                      <span className="text-muted-foreground text-xs">
                        {model.description}
                      </span>
                    )}
                  </div>
                </CommandItem>
              ))}
            </CommandGroup>
          </CommandList>
        </Command>
      </PopoverContent>
    </Popover>
  );
});
