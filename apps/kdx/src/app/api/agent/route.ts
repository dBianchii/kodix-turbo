import { openai } from "@ai-sdk/openai";
import { streamText } from "ai";

// Tipos para as mensagens
interface Message {
  role: string;
  content: string;
}

export async function POST(req: Request) {
  try {
    console.log("ðŸ”µ [API] POST recebido");

    const { messages } = await req.json();
    console.log("ðŸŸ¢ [API] Mensagens recebidas:", messages);

    // ObtÃ©m a Ãºltima mensagem do usuÃ¡rio
    const lastUserMessage =
      messages.filter((m: Message) => m.role === "user").pop()?.content || "";
    console.log("ðŸŸ¢ [API] Ãšltima mensagem do usuÃ¡rio:", lastUserMessage);

    // Verificando a chave da API
    const apiKey = process.env.OPENAI_API_KEY;
    if (
      !apiKey ||
      apiKey === "sk-sua-chave-aqui" ||
      apiKey.startsWith("sk-sua")
    ) {
      console.error("âŒ [API] OPENAI_API_KEY nÃ£o encontrada ou invÃ¡lida");
      return new Response(
        "Erro de configuraÃ§Ã£o: Chave da API OpenAI nÃ£o configurada.",
        {
          status: 500,
          headers: { "Content-Type": "text/plain; charset=utf-8" },
        },
      );
    }

    console.log("âœ… [API] OPENAI_API_KEY encontrada, processando...");

    try {
      // Mapeamento de "agent" para "assistant" para compatibilidade com a OpenAI
      const formattedMessages = messages.map((msg: Message) => ({
        role: msg.role === "agent" ? "assistant" : msg.role,
        content: msg.content,
      }));

      // Usando a biblioteca AI.js para criar o stream
      const result = await streamText({
        model: openai("gpt-3.5-turbo"),
        messages: formattedMessages,
      });

      console.log("ðŸŸ¢ [API] Stream criado com sucesso");

      // Criando um stream legÃ­vel para transmitir para o cliente
      const stream = new ReadableStream({
        async start(controller) {
          console.log("ðŸŸ¢ [API] Iniciando stream de resposta");
          try {
            // Verificar se houve resposta
            let receivedAnyChunk = false;

            // Iterando pelos chunks de texto do stream
            for await (const chunk of result.textStream) {
              receivedAnyChunk = true;
              // console.log("ðŸŸ  [API] Chunk sendo enviado:", chunk);

              // Encodando o chunk em bytes para o stream
              const encodedChunk = new TextEncoder().encode(chunk);
              controller.enqueue(encodedChunk);
            }

            // Se nÃ£o recebeu nenhum chunk, informa erro de conexÃ£o
            if (!receivedAnyChunk) {
              controller.enqueue(
                new TextEncoder().encode(
                  "Sem conexÃ£o. Verifique sua internet e tente novamente.",
                ),
              );
            }

            console.log("ðŸŸ¢ [API] Stream completo, fechando controller");
            controller.close();
          } catch (streamError) {
            console.error("ðŸ”´ [API] Erro no streaming:", streamError);
            controller.enqueue(
              new TextEncoder().encode("Erro de conexÃ£o. Tente novamente."),
            );
            controller.close();
          }
        },
      });

      // Retornando a resposta como stream
      return new Response(stream, {
        headers: {
          "Content-Type": "text/plain; charset=utf-8",
          "Cache-Control": "no-cache",
        },
      });
    } catch (aiError: any) {
      console.error("ðŸ”´ [API] Erro ao criar stream com OpenAI:", aiError);
      return new Response("Erro de conexÃ£o com a OpenAI. Tente novamente.", {
        status: 500,
        headers: { "Content-Type": "text/plain; charset=utf-8" },
      });
    }
  } catch (error: any) {
    console.error("ðŸ”´ [API] Erro geral:", error);
    return new Response("Erro de conexÃ£o. Tente novamente.", {
      status: 500,
      headers: { "Content-Type": "text/plain; charset=utf-8" },
    });
  }
}
